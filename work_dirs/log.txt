[01/11 20:45:58] MIX INFO: Rank of current process: 0. World size: 1
[01/11 20:45:58] MIX INFO: Rank of current process: 0. World size: 1
[01/11 20:45:58] MIX INFO: Environment info:
-----------------------------------------  ---------------------------------------------------------------------------------------
sys.platform                               linux
Python                                     3.8.5 (default, Sep  4 2020, 07:30:14) [GCC 7.3.0]
numpy                                      1.19.4
detectron2                                 failed to import
detectron2._C                              failed to import
Compiler                                   c++ (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)
CUDA compiler                              Cuda compilation tools, release 10.1, V10.1.243
DETECTRON2_ENV_MODULE                      <not set>
PyTorch                                    1.7.1+cu101 @/home/zrz/miniconda3/envs/MIX_py38/lib/python3.8/site-packages/torch
PyTorch debug build                        False
GPU available                              True
GPU 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15  Tesla V100-SXM3-32GB
CUDA_HOME                                  /usr/local/cuda
Pillow                                     8.0.1
torchvision                                0.8.2+cu101 @/home/zrz/miniconda3/envs/MIX_py38/lib/python3.8/site-packages/torchvision
torchvision arch flags                     sm_35, sm_50, sm_60, sm_70, sm_75
cv2                                        4.2.0
-----------------------------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON,

[01/11 20:45:58] MIX INFO: Environment info:
-----------------------------------------  ---------------------------------------------------------------------------------------
sys.platform                               linux
Python                                     3.8.5 (default, Sep  4 2020, 07:30:14) [GCC 7.3.0]
numpy                                      1.19.4
detectron2                                 failed to import
detectron2._C                              failed to import
Compiler                                   c++ (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)
CUDA compiler                              Cuda compilation tools, release 10.1, V10.1.243
DETECTRON2_ENV_MODULE                      <not set>
PyTorch                                    1.7.1+cu101 @/home/zrz/miniconda3/envs/MIX_py38/lib/python3.8/site-packages/torch
PyTorch debug build                        False
GPU available                              True
GPU 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15  Tesla V100-SXM3-32GB
CUDA_HOME                                  /usr/local/cuda
Pillow                                     8.0.1
torchvision                                0.8.2+cu101 @/home/zrz/miniconda3/envs/MIX_py38/lib/python3.8/site-packages/torchvision
torchvision arch flags                     sm_35, sm_50, sm_60, sm_70, sm_75
cv2                                        4.2.0
-----------------------------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON,

[01/11 20:45:58] MIX INFO: Command line arguments: Namespace(config='/home/jinliang/code/Mix/mix/configs/mcan/mcan_vqa.py', eval_only=False, gpu_ids=None, gpus=None, launcher='none', local_rank=0, no_validate=False, resume_from=None, seed=None, work_dir='/home/zrz/Mix/mix/work_dirs')
[01/11 20:45:58] MIX INFO: Command line arguments: Namespace(config='/home/jinliang/code/Mix/mix/configs/mcan/mcan_vqa.py', eval_only=False, gpu_ids=None, gpus=None, launcher='none', local_rank=0, no_validate=False, resume_from=None, seed=None, work_dir='/home/zrz/Mix/mix/work_dirs')
[01/11 20:45:58] MIX INFO: Running with full config:
Config (path: /home/jinliang/code/Mix/mix/configs/mcan/mcan_vqa.py): {'model': {'type': 'MCAN', 'embedding': [{'type': 'WordEmbedding', 'vocab_file': '~/.cache/torch/mmf/data/datasets/textvqa/defaults/extras/vocabs/vocabulary_100k.txt', 'embedding_dim': 300}, {'type': 'TextEmbedding', 'emb_type': 'mcan', 'hidden_dim': 1024, 'embedding_dim': 300, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'num_attn_pool': 1, 'num_feat': 2}], 'encoder': {'type': 'ImageFeatureEncoder', 'encoder_type': 'default'}, 'backbone': {'type': 'TwoBranchEmbedding', 'embedding_dim': 2048, 'hidden_dim': 1024, 'cond_dim': 1024, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'cbn_num_layers': 4}, 'combine_model': {'type': 'BranchCombineLayer', 'img_dim': 1024, 'ques_dim': 1024}, 'head': {'type': 'TripleLinearHead', 'in_dim': 2048, 'out_dim': 3129, 'loss_cls': {'type': 'TripleLogitBinaryCrossEntropy'}}}, 'dataset_type': 'VQADATASET', 'data_root': '~/.cache/torch/mmf/', 'feature_path': 'data/datasets/vqa2/grid_features/features/', 'annotation_path': 'data/datasets/vqa2/grid_features/annotations/', 'vocab_path': 'data/datasets/vqa2/defaults/extras/vocabs/', 'train_datasets': ['train'], 'test_datasets': ['oneval'], 'vqa_reader_train_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train']}, 'vqa_reader_test_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler_cfg': {'type': 'VQAInfoCpler', 'glove_weights': '~/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'train_data': {'samples_per_gpu': 16, 'workers_per_gpu': 1, 'sampler_name': 'TrainingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '~/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'limit_nums': 800}}, 'test_data': {'samples_per_gpu': 16, 'workers_per_gpu': 1, 'sampler_name': 'TestingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '~/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}, 'eval_period': 5000}, 'evaluator_type': 'VQA', 'optimizer': {'type': 'AdamW', 'lr': 5e-05, 'weight_decay': 0, 'eps': 1e-09, 'betas': [0.9, 0.98], 'training_encoder_lr_multiply': 1}, 'optimizer_config': {'grad_clip': None}, 'lr_config': {'use_warmup': True, 'lr_steps': [90000, 108000], 'lr_ratio': 0.2, 'warmup_factor': 0.25, 'warmup_iterations': 27000, 'policy': 'MultiStepScheduler'}, 'total_epochs': 4, 'checkpoint_config': {'period': 5000}, 'log_config': {'period': 5, 'hooks': [{'type': 'TextLoggerHook'}]}, 'dist_params': {'backend': 'nccl'}, 'log_level': 'INFO', 'work_dir': '/home/zrz/Mix/mix/work_dirs', 'load_from': '/home/jinliang/code/Mix/mix/work_dir/model_epoch3.pth', 'resume_from': None, 'workflow': [('train', 1)], 'seed': 39189013, 'CUDNN_BENCHMARK': False, 'model_device': 'cuda', 'find_unused_parameters': True, 'eval_only': False, 'gpu_ids': range(0, 1), 'distributed': False}
[01/11 20:45:58] MIX INFO: Running with full config:
Config (path: /home/jinliang/code/Mix/mix/configs/mcan/mcan_vqa.py): {'model': {'type': 'MCAN', 'embedding': [{'type': 'WordEmbedding', 'vocab_file': '~/.cache/torch/mmf/data/datasets/textvqa/defaults/extras/vocabs/vocabulary_100k.txt', 'embedding_dim': 300}, {'type': 'TextEmbedding', 'emb_type': 'mcan', 'hidden_dim': 1024, 'embedding_dim': 300, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'num_attn_pool': 1, 'num_feat': 2}], 'encoder': {'type': 'ImageFeatureEncoder', 'encoder_type': 'default'}, 'backbone': {'type': 'TwoBranchEmbedding', 'embedding_dim': 2048, 'hidden_dim': 1024, 'cond_dim': 1024, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'cbn_num_layers': 4}, 'combine_model': {'type': 'BranchCombineLayer', 'img_dim': 1024, 'ques_dim': 1024}, 'head': {'type': 'TripleLinearHead', 'in_dim': 2048, 'out_dim': 3129, 'loss_cls': {'type': 'TripleLogitBinaryCrossEntropy'}}}, 'dataset_type': 'VQADATASET', 'data_root': '~/.cache/torch/mmf/', 'feature_path': 'data/datasets/vqa2/grid_features/features/', 'annotation_path': 'data/datasets/vqa2/grid_features/annotations/', 'vocab_path': 'data/datasets/vqa2/defaults/extras/vocabs/', 'train_datasets': ['train'], 'test_datasets': ['oneval'], 'vqa_reader_train_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train']}, 'vqa_reader_test_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler_cfg': {'type': 'VQAInfoCpler', 'glove_weights': '~/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'train_data': {'samples_per_gpu': 16, 'workers_per_gpu': 1, 'sampler_name': 'TrainingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '~/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'limit_nums': 800}}, 'test_data': {'samples_per_gpu': 16, 'workers_per_gpu': 1, 'sampler_name': 'TestingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '~/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}, 'eval_period': 5000}, 'evaluator_type': 'VQA', 'optimizer': {'type': 'AdamW', 'lr': 5e-05, 'weight_decay': 0, 'eps': 1e-09, 'betas': [0.9, 0.98], 'training_encoder_lr_multiply': 1}, 'optimizer_config': {'grad_clip': None}, 'lr_config': {'use_warmup': True, 'lr_steps': [90000, 108000], 'lr_ratio': 0.2, 'warmup_factor': 0.25, 'warmup_iterations': 27000, 'policy': 'MultiStepScheduler'}, 'total_epochs': 4, 'checkpoint_config': {'period': 5000}, 'log_config': {'period': 5, 'hooks': [{'type': 'TextLoggerHook'}]}, 'dist_params': {'backend': 'nccl'}, 'log_level': 'INFO', 'work_dir': '/home/zrz/Mix/mix/work_dirs', 'load_from': '/home/jinliang/code/Mix/mix/work_dir/model_epoch3.pth', 'resume_from': None, 'workflow': [('train', 1)], 'seed': 39189013, 'CUDNN_BENCHMARK': False, 'model_device': 'cuda', 'find_unused_parameters': True, 'eval_only': False, 'gpu_ids': range(0, 1), 'distributed': False}
[01/11 20:46:08] MIX INFO: Full config saved to /home/zrz/Mix/mix/work_dirs/config.yaml
[01/11 20:46:08] MIX INFO: Full config saved to /home/zrz/Mix/mix/work_dirs/config.yaml
[01/11 20:52:07] MIX INFO: Rank of current process: 0. World size: 1
[01/11 20:52:07] MIX INFO: Rank of current process: 0. World size: 1
[01/11 20:52:07] MIX INFO: Environment info:
-----------------------------------------  ---------------------------------------------------------------------------------------
sys.platform                               linux
Python                                     3.8.5 (default, Sep  4 2020, 07:30:14) [GCC 7.3.0]
numpy                                      1.19.4
detectron2                                 failed to import
detectron2._C                              failed to import
Compiler                                   c++ (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)
CUDA compiler                              Cuda compilation tools, release 10.1, V10.1.243
DETECTRON2_ENV_MODULE                      <not set>
PyTorch                                    1.7.1+cu101 @/home/zrz/miniconda3/envs/MIX_py38/lib/python3.8/site-packages/torch
PyTorch debug build                        False
GPU available                              True
GPU 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15  Tesla V100-SXM3-32GB
CUDA_HOME                                  /usr/local/cuda
Pillow                                     8.0.1
torchvision                                0.8.2+cu101 @/home/zrz/miniconda3/envs/MIX_py38/lib/python3.8/site-packages/torchvision
torchvision arch flags                     sm_35, sm_50, sm_60, sm_70, sm_75
cv2                                        4.2.0
-----------------------------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON,

[01/11 20:52:07] MIX INFO: Environment info:
-----------------------------------------  ---------------------------------------------------------------------------------------
sys.platform                               linux
Python                                     3.8.5 (default, Sep  4 2020, 07:30:14) [GCC 7.3.0]
numpy                                      1.19.4
detectron2                                 failed to import
detectron2._C                              failed to import
Compiler                                   c++ (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)
CUDA compiler                              Cuda compilation tools, release 10.1, V10.1.243
DETECTRON2_ENV_MODULE                      <not set>
PyTorch                                    1.7.1+cu101 @/home/zrz/miniconda3/envs/MIX_py38/lib/python3.8/site-packages/torch
PyTorch debug build                        False
GPU available                              True
GPU 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15  Tesla V100-SXM3-32GB
CUDA_HOME                                  /usr/local/cuda
Pillow                                     8.0.1
torchvision                                0.8.2+cu101 @/home/zrz/miniconda3/envs/MIX_py38/lib/python3.8/site-packages/torchvision
torchvision arch flags                     sm_35, sm_50, sm_60, sm_70, sm_75
cv2                                        4.2.0
-----------------------------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON,

[01/11 20:52:07] MIX INFO: Command line arguments: Namespace(config='/home/jinliang/code/Mix/mix/configs/mcan/mcan_vqa.py', eval_only=False, gpu_ids=None, gpus=None, launcher='none', local_rank=0, no_validate=False, resume_from=None, seed=None, work_dir='/home/zrz/Mix/mix/work_dirs')
[01/11 20:52:07] MIX INFO: Command line arguments: Namespace(config='/home/jinliang/code/Mix/mix/configs/mcan/mcan_vqa.py', eval_only=False, gpu_ids=None, gpus=None, launcher='none', local_rank=0, no_validate=False, resume_from=None, seed=None, work_dir='/home/zrz/Mix/mix/work_dirs')
[01/11 20:52:07] MIX INFO: Running with full config:
Config (path: /home/jinliang/code/Mix/mix/configs/mcan/mcan_vqa.py): {'model': {'type': 'MCAN', 'embedding': [{'type': 'WordEmbedding', 'vocab_file': '~/.cache/torch/mmf/data/datasets/textvqa/defaults/extras/vocabs/vocabulary_100k.txt', 'embedding_dim': 300}, {'type': 'TextEmbedding', 'emb_type': 'mcan', 'hidden_dim': 1024, 'embedding_dim': 300, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'num_attn_pool': 1, 'num_feat': 2}], 'encoder': {'type': 'ImageFeatureEncoder', 'encoder_type': 'default'}, 'backbone': {'type': 'TwoBranchEmbedding', 'embedding_dim': 2048, 'hidden_dim': 1024, 'cond_dim': 1024, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'cbn_num_layers': 4}, 'combine_model': {'type': 'BranchCombineLayer', 'img_dim': 1024, 'ques_dim': 1024}, 'head': {'type': 'TripleLinearHead', 'in_dim': 2048, 'out_dim': 3129, 'loss_cls': {'type': 'TripleLogitBinaryCrossEntropy'}}}, 'dataset_type': 'VQADATASET', 'data_root': '~/.cache/torch/mmf/', 'feature_path': 'data/datasets/vqa2/grid_features/features/', 'annotation_path': 'data/datasets/vqa2/grid_features/annotations/', 'vocab_path': 'data/datasets/vqa2/defaults/extras/vocabs/', 'train_datasets': ['train'], 'test_datasets': ['oneval'], 'vqa_reader_train_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train']}, 'vqa_reader_test_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler_cfg': {'type': 'VQAInfoCpler', 'glove_weights': '~/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'train_data': {'samples_per_gpu': 16, 'workers_per_gpu': 1, 'sampler_name': 'TrainingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '~/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'limit_nums': 800}}, 'test_data': {'samples_per_gpu': 16, 'workers_per_gpu': 1, 'sampler_name': 'TestingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '~/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}, 'eval_period': 5000}, 'evaluator_type': 'VQA', 'optimizer': {'type': 'AdamW', 'lr': 5e-05, 'weight_decay': 0, 'eps': 1e-09, 'betas': [0.9, 0.98], 'training_encoder_lr_multiply': 1}, 'optimizer_config': {'grad_clip': None}, 'lr_config': {'use_warmup': True, 'lr_steps': [90000, 108000], 'lr_ratio': 0.2, 'warmup_factor': 0.25, 'warmup_iterations': 27000, 'policy': 'MultiStepScheduler'}, 'total_epochs': 4, 'checkpoint_config': {'period': 5000}, 'log_config': {'period': 5, 'hooks': [{'type': 'TextLoggerHook'}]}, 'dist_params': {'backend': 'nccl'}, 'log_level': 'INFO', 'work_dir': '/home/zrz/Mix/mix/work_dirs', 'load_from': '/home/jinliang/code/Mix/mix/work_dir/model_epoch3.pth', 'resume_from': None, 'workflow': [('train', 1)], 'seed': 39189013, 'CUDNN_BENCHMARK': False, 'model_device': 'cuda', 'find_unused_parameters': True, 'eval_only': False, 'gpu_ids': range(0, 1), 'distributed': False}
[01/11 20:52:07] MIX INFO: Running with full config:
Config (path: /home/jinliang/code/Mix/mix/configs/mcan/mcan_vqa.py): {'model': {'type': 'MCAN', 'embedding': [{'type': 'WordEmbedding', 'vocab_file': '~/.cache/torch/mmf/data/datasets/textvqa/defaults/extras/vocabs/vocabulary_100k.txt', 'embedding_dim': 300}, {'type': 'TextEmbedding', 'emb_type': 'mcan', 'hidden_dim': 1024, 'embedding_dim': 300, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'num_attn_pool': 1, 'num_feat': 2}], 'encoder': {'type': 'ImageFeatureEncoder', 'encoder_type': 'default'}, 'backbone': {'type': 'TwoBranchEmbedding', 'embedding_dim': 2048, 'hidden_dim': 1024, 'cond_dim': 1024, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'cbn_num_layers': 4}, 'combine_model': {'type': 'BranchCombineLayer', 'img_dim': 1024, 'ques_dim': 1024}, 'head': {'type': 'TripleLinearHead', 'in_dim': 2048, 'out_dim': 3129, 'loss_cls': {'type': 'TripleLogitBinaryCrossEntropy'}}}, 'dataset_type': 'VQADATASET', 'data_root': '~/.cache/torch/mmf/', 'feature_path': 'data/datasets/vqa2/grid_features/features/', 'annotation_path': 'data/datasets/vqa2/grid_features/annotations/', 'vocab_path': 'data/datasets/vqa2/defaults/extras/vocabs/', 'train_datasets': ['train'], 'test_datasets': ['oneval'], 'vqa_reader_train_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train']}, 'vqa_reader_test_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler_cfg': {'type': 'VQAInfoCpler', 'glove_weights': '~/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'train_data': {'samples_per_gpu': 16, 'workers_per_gpu': 1, 'sampler_name': 'TrainingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '~/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'limit_nums': 800}}, 'test_data': {'samples_per_gpu': 16, 'workers_per_gpu': 1, 'sampler_name': 'TestingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '~/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}, 'eval_period': 5000}, 'evaluator_type': 'VQA', 'optimizer': {'type': 'AdamW', 'lr': 5e-05, 'weight_decay': 0, 'eps': 1e-09, 'betas': [0.9, 0.98], 'training_encoder_lr_multiply': 1}, 'optimizer_config': {'grad_clip': None}, 'lr_config': {'use_warmup': True, 'lr_steps': [90000, 108000], 'lr_ratio': 0.2, 'warmup_factor': 0.25, 'warmup_iterations': 27000, 'policy': 'MultiStepScheduler'}, 'total_epochs': 4, 'checkpoint_config': {'period': 5000}, 'log_config': {'period': 5, 'hooks': [{'type': 'TextLoggerHook'}]}, 'dist_params': {'backend': 'nccl'}, 'log_level': 'INFO', 'work_dir': '/home/zrz/Mix/mix/work_dirs', 'load_from': '/home/jinliang/code/Mix/mix/work_dir/model_epoch3.pth', 'resume_from': None, 'workflow': [('train', 1)], 'seed': 39189013, 'CUDNN_BENCHMARK': False, 'model_device': 'cuda', 'find_unused_parameters': True, 'eval_only': False, 'gpu_ids': range(0, 1), 'distributed': False}
[01/11 20:52:17] MIX INFO: Full config saved to /home/zrz/Mix/mix/work_dirs/config.yaml
[01/11 20:52:17] MIX INFO: Full config saved to /home/zrz/Mix/mix/work_dirs/config.yaml
[01/11 20:53:22] MIX INFO: Rank of current process: 0. World size: 1
[01/11 20:53:22] MIX INFO: Rank of current process: 0. World size: 1
[01/11 20:53:22] MIX INFO: Environment info:
-----------------------------------------  ---------------------------------------------------------------------------------------
sys.platform                               linux
Python                                     3.8.5 (default, Sep  4 2020, 07:30:14) [GCC 7.3.0]
numpy                                      1.19.4
detectron2                                 failed to import
detectron2._C                              failed to import
Compiler                                   c++ (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)
CUDA compiler                              Cuda compilation tools, release 10.1, V10.1.243
DETECTRON2_ENV_MODULE                      <not set>
PyTorch                                    1.7.1+cu101 @/home/zrz/miniconda3/envs/MIX_py38/lib/python3.8/site-packages/torch
PyTorch debug build                        False
GPU available                              True
GPU 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15  Tesla V100-SXM3-32GB
CUDA_HOME                                  /usr/local/cuda
Pillow                                     8.0.1
torchvision                                0.8.2+cu101 @/home/zrz/miniconda3/envs/MIX_py38/lib/python3.8/site-packages/torchvision
torchvision arch flags                     sm_35, sm_50, sm_60, sm_70, sm_75
cv2                                        4.2.0
-----------------------------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON,

[01/11 20:53:22] MIX INFO: Environment info:
-----------------------------------------  ---------------------------------------------------------------------------------------
sys.platform                               linux
Python                                     3.8.5 (default, Sep  4 2020, 07:30:14) [GCC 7.3.0]
numpy                                      1.19.4
detectron2                                 failed to import
detectron2._C                              failed to import
Compiler                                   c++ (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)
CUDA compiler                              Cuda compilation tools, release 10.1, V10.1.243
DETECTRON2_ENV_MODULE                      <not set>
PyTorch                                    1.7.1+cu101 @/home/zrz/miniconda3/envs/MIX_py38/lib/python3.8/site-packages/torch
PyTorch debug build                        False
GPU available                              True
GPU 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15  Tesla V100-SXM3-32GB
CUDA_HOME                                  /usr/local/cuda
Pillow                                     8.0.1
torchvision                                0.8.2+cu101 @/home/zrz/miniconda3/envs/MIX_py38/lib/python3.8/site-packages/torchvision
torchvision arch flags                     sm_35, sm_50, sm_60, sm_70, sm_75
cv2                                        4.2.0
-----------------------------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON,

[01/11 20:53:22] MIX INFO: Command line arguments: Namespace(config='/home/jinliang/code/Mix/mix/configs/mcan/mcan_vqa.py', eval_only=False, gpu_ids=None, gpus=None, launcher='none', local_rank=0, no_validate=False, resume_from=None, seed=None, work_dir='/home/zrz/Mix/mix/work_dirs')
[01/11 20:53:22] MIX INFO: Command line arguments: Namespace(config='/home/jinliang/code/Mix/mix/configs/mcan/mcan_vqa.py', eval_only=False, gpu_ids=None, gpus=None, launcher='none', local_rank=0, no_validate=False, resume_from=None, seed=None, work_dir='/home/zrz/Mix/mix/work_dirs')
[01/11 20:53:22] MIX INFO: Running with full config:
Config (path: /home/jinliang/code/Mix/mix/configs/mcan/mcan_vqa.py): {'model': {'type': 'MCAN', 'embedding': [{'type': 'WordEmbedding', 'vocab_file': '~/.cache/torch/mmf/data/datasets/textvqa/defaults/extras/vocabs/vocabulary_100k.txt', 'embedding_dim': 300}, {'type': 'TextEmbedding', 'emb_type': 'mcan', 'hidden_dim': 1024, 'embedding_dim': 300, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'num_attn_pool': 1, 'num_feat': 2}], 'encoder': {'type': 'ImageFeatureEncoder', 'encoder_type': 'default'}, 'backbone': {'type': 'TwoBranchEmbedding', 'embedding_dim': 2048, 'hidden_dim': 1024, 'cond_dim': 1024, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'cbn_num_layers': 4}, 'combine_model': {'type': 'BranchCombineLayer', 'img_dim': 1024, 'ques_dim': 1024}, 'head': {'type': 'TripleLinearHead', 'in_dim': 2048, 'out_dim': 3129, 'loss_cls': {'type': 'TripleLogitBinaryCrossEntropy'}}}, 'dataset_type': 'VQADATASET', 'data_root': '~/.cache/torch/mmf/', 'feature_path': 'data/datasets/vqa2/grid_features/features/', 'annotation_path': 'data/datasets/vqa2/grid_features/annotations/', 'vocab_path': 'data/datasets/vqa2/defaults/extras/vocabs/', 'train_datasets': ['train'], 'test_datasets': ['oneval'], 'vqa_reader_train_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train']}, 'vqa_reader_test_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler_cfg': {'type': 'VQAInfoCpler', 'glove_weights': '~/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'train_data': {'samples_per_gpu': 16, 'workers_per_gpu': 1, 'sampler_name': 'TrainingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '~/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'limit_nums': 800}}, 'test_data': {'samples_per_gpu': 16, 'workers_per_gpu': 1, 'sampler_name': 'TestingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '~/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}, 'eval_period': 5000}, 'evaluator_type': 'VQA', 'optimizer': {'type': 'AdamW', 'lr': 5e-05, 'weight_decay': 0, 'eps': 1e-09, 'betas': [0.9, 0.98], 'training_encoder_lr_multiply': 1}, 'optimizer_config': {'grad_clip': None}, 'lr_config': {'use_warmup': True, 'lr_steps': [90000, 108000], 'lr_ratio': 0.2, 'warmup_factor': 0.25, 'warmup_iterations': 27000, 'policy': 'MultiStepScheduler'}, 'total_epochs': 4, 'checkpoint_config': {'period': 5000}, 'log_config': {'period': 5, 'hooks': [{'type': 'TextLoggerHook'}]}, 'dist_params': {'backend': 'nccl'}, 'log_level': 'INFO', 'work_dir': '/home/zrz/Mix/mix/work_dirs', 'load_from': '/home/jinliang/code/Mix/mix/work_dir/model_epoch3.pth', 'resume_from': None, 'workflow': [('train', 1)], 'seed': 39189013, 'CUDNN_BENCHMARK': False, 'model_device': 'cuda', 'find_unused_parameters': True, 'eval_only': False, 'gpu_ids': range(0, 1), 'distributed': False}
[01/11 20:53:22] MIX INFO: Running with full config:
Config (path: /home/jinliang/code/Mix/mix/configs/mcan/mcan_vqa.py): {'model': {'type': 'MCAN', 'embedding': [{'type': 'WordEmbedding', 'vocab_file': '~/.cache/torch/mmf/data/datasets/textvqa/defaults/extras/vocabs/vocabulary_100k.txt', 'embedding_dim': 300}, {'type': 'TextEmbedding', 'emb_type': 'mcan', 'hidden_dim': 1024, 'embedding_dim': 300, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'num_attn_pool': 1, 'num_feat': 2}], 'encoder': {'type': 'ImageFeatureEncoder', 'encoder_type': 'default'}, 'backbone': {'type': 'TwoBranchEmbedding', 'embedding_dim': 2048, 'hidden_dim': 1024, 'cond_dim': 1024, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'cbn_num_layers': 4}, 'combine_model': {'type': 'BranchCombineLayer', 'img_dim': 1024, 'ques_dim': 1024}, 'head': {'type': 'TripleLinearHead', 'in_dim': 2048, 'out_dim': 3129, 'loss_cls': {'type': 'TripleLogitBinaryCrossEntropy'}}}, 'dataset_type': 'VQADATASET', 'data_root': '~/.cache/torch/mmf/', 'feature_path': 'data/datasets/vqa2/grid_features/features/', 'annotation_path': 'data/datasets/vqa2/grid_features/annotations/', 'vocab_path': 'data/datasets/vqa2/defaults/extras/vocabs/', 'train_datasets': ['train'], 'test_datasets': ['oneval'], 'vqa_reader_train_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train']}, 'vqa_reader_test_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler_cfg': {'type': 'VQAInfoCpler', 'glove_weights': '~/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'train_data': {'samples_per_gpu': 16, 'workers_per_gpu': 1, 'sampler_name': 'TrainingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '~/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'limit_nums': 800}}, 'test_data': {'samples_per_gpu': 16, 'workers_per_gpu': 1, 'sampler_name': 'TestingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '~/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}, 'eval_period': 5000}, 'evaluator_type': 'VQA', 'optimizer': {'type': 'AdamW', 'lr': 5e-05, 'weight_decay': 0, 'eps': 1e-09, 'betas': [0.9, 0.98], 'training_encoder_lr_multiply': 1}, 'optimizer_config': {'grad_clip': None}, 'lr_config': {'use_warmup': True, 'lr_steps': [90000, 108000], 'lr_ratio': 0.2, 'warmup_factor': 0.25, 'warmup_iterations': 27000, 'policy': 'MultiStepScheduler'}, 'total_epochs': 4, 'checkpoint_config': {'period': 5000}, 'log_config': {'period': 5, 'hooks': [{'type': 'TextLoggerHook'}]}, 'dist_params': {'backend': 'nccl'}, 'log_level': 'INFO', 'work_dir': '/home/zrz/Mix/mix/work_dirs', 'load_from': '/home/jinliang/code/Mix/mix/work_dir/model_epoch3.pth', 'resume_from': None, 'workflow': [('train', 1)], 'seed': 39189013, 'CUDNN_BENCHMARK': False, 'model_device': 'cuda', 'find_unused_parameters': True, 'eval_only': False, 'gpu_ids': range(0, 1), 'distributed': False}
[01/11 20:54:10] MIX INFO: Full config saved to /home/zrz/Mix/mix/work_dirs/config.yaml
[01/11 20:54:10] MIX INFO: Full config saved to /home/zrz/Mix/mix/work_dirs/config.yaml
[01/25 02:59:57] MIX INFO: Rank of current process: 0. World size: 1
[01/25 02:59:57] MIX INFO: Rank of current process: 0. World size: 1
[01/25 02:59:57] MIX INFO: Environment info:
-----------------------------------------  ---------------------------------------------------------------------------------------
sys.platform                               linux
Python                                     3.8.5 (default, Sep  4 2020, 07:30:14) [GCC 7.3.0]
numpy                                      1.19.4
detectron2                                 failed to import
detectron2._C                              failed to import
Compiler                                   c++ (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)
CUDA compiler                              Cuda compilation tools, release 10.1, V10.1.243
DETECTRON2_ENV_MODULE                      <not set>
PyTorch                                    1.7.1+cu101 @/home/zrz/miniconda3/envs/MIX_py38/lib/python3.8/site-packages/torch
PyTorch debug build                        False
GPU available                              True
GPU 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15  Tesla V100-SXM3-32GB
CUDA_HOME                                  /usr/local/cuda
Pillow                                     8.0.1
torchvision                                0.8.2+cu101 @/home/zrz/miniconda3/envs/MIX_py38/lib/python3.8/site-packages/torchvision
torchvision arch flags                     sm_35, sm_50, sm_60, sm_70, sm_75
cv2                                        4.2.0
-----------------------------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON,

[01/25 02:59:57] MIX INFO: Environment info:
-----------------------------------------  ---------------------------------------------------------------------------------------
sys.platform                               linux
Python                                     3.8.5 (default, Sep  4 2020, 07:30:14) [GCC 7.3.0]
numpy                                      1.19.4
detectron2                                 failed to import
detectron2._C                              failed to import
Compiler                                   c++ (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)
CUDA compiler                              Cuda compilation tools, release 10.1, V10.1.243
DETECTRON2_ENV_MODULE                      <not set>
PyTorch                                    1.7.1+cu101 @/home/zrz/miniconda3/envs/MIX_py38/lib/python3.8/site-packages/torch
PyTorch debug build                        False
GPU available                              True
GPU 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15  Tesla V100-SXM3-32GB
CUDA_HOME                                  /usr/local/cuda
Pillow                                     8.0.1
torchvision                                0.8.2+cu101 @/home/zrz/miniconda3/envs/MIX_py38/lib/python3.8/site-packages/torchvision
torchvision arch flags                     sm_35, sm_50, sm_60, sm_70, sm_75
cv2                                        4.2.0
-----------------------------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON,

[01/25 02:59:57] MIX INFO: Command line arguments: Namespace(config='/home/jinliang/code/Mix/mix/configs/mcan/mcan_vqa.py', eval_only=False, gpu_ids=None, gpus=None, launcher='none', local_rank=0, no_validate=False, resume_from=None, seed=None, work_dir='/home/zrz/Mix/mix/work_dirs')
[01/25 02:59:57] MIX INFO: Command line arguments: Namespace(config='/home/jinliang/code/Mix/mix/configs/mcan/mcan_vqa.py', eval_only=False, gpu_ids=None, gpus=None, launcher='none', local_rank=0, no_validate=False, resume_from=None, seed=None, work_dir='/home/zrz/Mix/mix/work_dirs')
[01/25 02:59:57] MIX INFO: Running with full config:
Config (path: /home/jinliang/code/Mix/mix/configs/mcan/mcan_vqa.py): {'model': {'type': 'MCAN', 'embedding': [{'type': 'WordEmbedding', 'vocab_file': '~/.cache/torch/mmf/data/datasets/textvqa/defaults/extras/vocabs/vocabulary_100k.txt', 'embedding_dim': 300}, {'type': 'TextEmbedding', 'emb_type': 'mcan', 'hidden_dim': 1024, 'embedding_dim': 300, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'num_attn_pool': 1, 'num_feat': 2}], 'encoder': {'type': 'ImageFeatureEncoder', 'encoder_type': 'default'}, 'backbone': {'type': 'TwoBranchEmbedding', 'embedding_dim': 2048, 'hidden_dim': 1024, 'cond_dim': 1024, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'cbn_num_layers': 4}, 'combine_model': {'type': 'BranchCombineLayer', 'img_dim': 1024, 'ques_dim': 1024}, 'head': {'type': 'TripleLinearHead', 'in_dim': 2048, 'out_dim': 3129, 'loss_cls': {'type': 'TripleLogitBinaryCrossEntropy'}}}, 'dataset_type': 'VQADATASET', 'data_root': '~/.cache/torch/mmf/', 'feature_path': 'data/datasets/vqa2/grid_features/features/', 'annotation_path': 'data/datasets/vqa2/grid_features/annotations/', 'vocab_path': 'data/datasets/vqa2/defaults/extras/vocabs/', 'train_datasets': ['train', 'val', 'visualgenome'], 'test_datasets': ['oneval'], 'vqa_reader_train_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val', 'visualgenome']}, 'vqa_reader_test_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler_cfg': {'type': 'VQAInfoCpler', 'glove_weights': '~/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'train_data': {'samples_per_gpu': 16, 'workers_per_gpu': 2, 'sampler_name': 'TrainingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val', 'visualgenome']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '~/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}}, 'test_data': {'samples_per_gpu': 16, 'workers_per_gpu': 2, 'sampler_name': 'TestingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '~/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}, 'eval_period': 5000}, 'evaluator_type': 'VQA', 'optimizer': {'type': 'AdamW', 'lr': 5e-05, 'weight_decay': 0, 'eps': 1e-09, 'betas': [0.9, 0.98], 'training_encoder_lr_multiply': 1}, 'optimizer_config': {'grad_clip': None}, 'lr_config': {'use_warmup': True, 'lr_steps': [90000, 108000], 'lr_ratio': 0.2, 'warmup_factor': 0.25, 'warmup_iterations': 27000, 'policy': 'MultiStepScheduler'}, 'total_epochs': 12, 'checkpoint_config': {'period': 5000}, 'log_config': {'period': 500, 'hooks': [{'type': 'TextLoggerHook'}]}, 'dist_params': {'backend': 'nccl'}, 'log_level': 'INFO', 'work_dir': '/home/zrz/Mix/mix/work_dirs', 'load_from': '/home/jinliang/code/Mix/mix/work_dir/model_epoch3.pth', 'resume_from': None, 'workflow': [('train', 1)], 'seed': 39189013, 'CUDNN_BENCHMARK': False, 'model_device': 'cuda', 'find_unused_parameters': True, 'eval_only': False, 'gpu_ids': range(0, 1), 'distributed': False}
[01/25 02:59:57] MIX INFO: Running with full config:
Config (path: /home/jinliang/code/Mix/mix/configs/mcan/mcan_vqa.py): {'model': {'type': 'MCAN', 'embedding': [{'type': 'WordEmbedding', 'vocab_file': '~/.cache/torch/mmf/data/datasets/textvqa/defaults/extras/vocabs/vocabulary_100k.txt', 'embedding_dim': 300}, {'type': 'TextEmbedding', 'emb_type': 'mcan', 'hidden_dim': 1024, 'embedding_dim': 300, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'num_attn_pool': 1, 'num_feat': 2}], 'encoder': {'type': 'ImageFeatureEncoder', 'encoder_type': 'default'}, 'backbone': {'type': 'TwoBranchEmbedding', 'embedding_dim': 2048, 'hidden_dim': 1024, 'cond_dim': 1024, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'cbn_num_layers': 4}, 'combine_model': {'type': 'BranchCombineLayer', 'img_dim': 1024, 'ques_dim': 1024}, 'head': {'type': 'TripleLinearHead', 'in_dim': 2048, 'out_dim': 3129, 'loss_cls': {'type': 'TripleLogitBinaryCrossEntropy'}}}, 'dataset_type': 'VQADATASET', 'data_root': '~/.cache/torch/mmf/', 'feature_path': 'data/datasets/vqa2/grid_features/features/', 'annotation_path': 'data/datasets/vqa2/grid_features/annotations/', 'vocab_path': 'data/datasets/vqa2/defaults/extras/vocabs/', 'train_datasets': ['train', 'val', 'visualgenome'], 'test_datasets': ['oneval'], 'vqa_reader_train_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val', 'visualgenome']}, 'vqa_reader_test_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler_cfg': {'type': 'VQAInfoCpler', 'glove_weights': '~/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'train_data': {'samples_per_gpu': 16, 'workers_per_gpu': 2, 'sampler_name': 'TrainingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val', 'visualgenome']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '~/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}}, 'test_data': {'samples_per_gpu': 16, 'workers_per_gpu': 2, 'sampler_name': 'TestingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '~/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '~/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '~/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}, 'eval_period': 5000}, 'evaluator_type': 'VQA', 'optimizer': {'type': 'AdamW', 'lr': 5e-05, 'weight_decay': 0, 'eps': 1e-09, 'betas': [0.9, 0.98], 'training_encoder_lr_multiply': 1}, 'optimizer_config': {'grad_clip': None}, 'lr_config': {'use_warmup': True, 'lr_steps': [90000, 108000], 'lr_ratio': 0.2, 'warmup_factor': 0.25, 'warmup_iterations': 27000, 'policy': 'MultiStepScheduler'}, 'total_epochs': 12, 'checkpoint_config': {'period': 5000}, 'log_config': {'period': 500, 'hooks': [{'type': 'TextLoggerHook'}]}, 'dist_params': {'backend': 'nccl'}, 'log_level': 'INFO', 'work_dir': '/home/zrz/Mix/mix/work_dirs', 'load_from': '/home/jinliang/code/Mix/mix/work_dir/model_epoch3.pth', 'resume_from': None, 'workflow': [('train', 1)], 'seed': 39189013, 'CUDNN_BENCHMARK': False, 'model_device': 'cuda', 'find_unused_parameters': True, 'eval_only': False, 'gpu_ids': range(0, 1), 'distributed': False}
