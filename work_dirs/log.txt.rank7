[11/19 20:12:01] MIX INFO: Rank of current process: 7. World size: 8
[11/19 20:12:01] MIX INFO: Rank of current process: 7. World size: 8
[11/19 20:12:01] MIX INFO: Environment info:
---------------------  ---------------------------------------------------------------------------------------
sys.platform           linux
Python                 3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 01:22:34) [GCC 7.3.0]
numpy                  1.18.5
detectron2             failed to import
detectron2._C          failed to import
Compiler               c++ (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)
CUDA compiler          Cuda compilation tools, release 10.1, V10.1.243
DETECTRON2_ENV_MODULE  <not set>
PyTorch                1.6.0+cu101 @/home/jinliang/miniconda3/envs/MIX/lib/python3.6/site-packages/torch
PyTorch debug build    False
GPU available          True
GPU 0,1,2,3            Tesla V100-PCIE-16GB
CUDA_HOME              /usr/local/cuda
Pillow                 6.2.2
torchvision            0.6.0+cu101 @/home/jinliang/miniconda3/envs/MIX/lib/python3.6/site-packages/torchvision
torchvision            unknown
cv2                    4.2.0
---------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF,

[11/19 20:12:01] MIX INFO: Environment info:
---------------------  ---------------------------------------------------------------------------------------
sys.platform           linux
Python                 3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 01:22:34) [GCC 7.3.0]
numpy                  1.18.5
detectron2             failed to import
detectron2._C          failed to import
Compiler               c++ (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)
CUDA compiler          Cuda compilation tools, release 10.1, V10.1.243
DETECTRON2_ENV_MODULE  <not set>
PyTorch                1.6.0+cu101 @/home/jinliang/miniconda3/envs/MIX/lib/python3.6/site-packages/torch
PyTorch debug build    False
GPU available          True
GPU 0,1,2,3            Tesla V100-PCIE-16GB
CUDA_HOME              /usr/local/cuda
Pillow                 6.2.2
torchvision            0.6.0+cu101 @/home/jinliang/miniconda3/envs/MIX/lib/python3.6/site-packages/torchvision
torchvision            unknown
cv2                    4.2.0
---------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF,

[11/19 20:12:01] MIX INFO: Command line arguments: Namespace(config_file='configs/mcan/mcan_vqa.py', dist_url='tcp://100.2.95.103:8686', eval_only=False, machine_rank=1, num_gpus=4, num_machines=2, opts=[], resume=False, work_dir=None)
[11/19 20:12:01] MIX INFO: Command line arguments: Namespace(config_file='configs/mcan/mcan_vqa.py', dist_url='tcp://100.2.95.103:8686', eval_only=False, machine_rank=1, num_gpus=4, num_machines=2, opts=[], resume=False, work_dir=None)
[11/19 20:12:01] MIX INFO: Contents of args.config_file=configs/mcan/mcan_vqa.py:
_base_ = [
    '../_base_/models/mcan_config.py',
    '../_base_/datasets/vqa_dataset.py',
    '../_base_/schedules/schedule_vqa.py',
    '../_base_/default_runtime.py'
] # yapf:disable

[11/19 20:12:01] MIX INFO: Contents of args.config_file=configs/mcan/mcan_vqa.py:
_base_ = [
    '../_base_/models/mcan_config.py',
    '../_base_/datasets/vqa_dataset.py',
    '../_base_/schedules/schedule_vqa.py',
    '../_base_/default_runtime.py'
] # yapf:disable

[11/19 20:12:01] MIX INFO: Running with full config:
Config (path: configs/mcan/mcan_vqa.py): {'model': {'type': 'MCAN', 'embedding': [{'type': 'WordEmbedding', 'vocab_file': '/home/jinliang/.cache/torch/mmf/data/datasets/textvqa/defaults/extras/vocabs/vocabulary_100k.txt', 'embedding_dim': 300}, {'type': 'TextEmbedding', 'emb_type': 'mcan', 'hidden_dim': 1024, 'embedding_dim': 300, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'num_attn_pool': 1, 'num_feat': 2}], 'encoder': {'type': 'ImageFeatureEncoder', 'encoder_type': 'default'}, 'backbone': {'type': 'TwoBranchEmbedding', 'embedding_dim': 2048, 'hidden_dim': 1024, 'cond_dim': 1024, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'cbn_num_layers': 4}, 'combine_model': {'type': 'BranchCombineLayer', 'img_dim': 1024, 'ques_dim': 1024}, 'head': {'type': 'ClassifierLayer', 'classifier_type': 'triple_linear', 'in_dim': 2048, 'out_dim': 3129}}, 'dataset_type': 'VQADATASET', 'data_root': '/home/jinliang/.cache/torch/mmf/', 'feature_path': 'data/datasets/vqa2/grid_features/features/', 'annotation_path': 'data/datasets/vqa2/grid_features/annotations/', 'vocab_path': 'data/datasets/vqa2/defaults/extras/vocabs/', 'train_datasets': ['train', 'val', 'visualgenome'], 'test_datasets': ['oneval'], 'vqa_reader_train_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val', 'visualgenome']}, 'vqa_reader_test_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler_cfg': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'train_data': {'samples_per_gpu': 4, 'workers_per_gpu': 1, 'sampler_name': 'TrainingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val', 'visualgenome']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'limit_nums': 400}}, 'test_data': {'samples_per_gpu': 4, 'workers_per_gpu': 1, 'sampler_name': 'TestingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}, 'eval_period': 50}, 'evaluator_type': 'VQA', 'optimizer': {'type': 'AdamW', 'lr': 5e-05, 'weight_decay': 0, 'eps': 1e-09, 'betas': [0.9, 0.98], 'training_encoder_lr_multiply': 1}, 'optimizer_config': {'grad_clip': None}, 'lr_config': {'use_warmup': True, 'lr_steps': [90000, 108000], 'lr_ratio': 0.2, 'warmup_factor': 0.25, 'warmup_iterations': 27000, 'policy': 'MultiStepScheduler'}, 'max_iter': 236000, 'by_iter': True, 'checkpoint_config': {'period': 5000}, 'log_config': {'period': 50, 'hooks': [{'type': 'TextLoggerHook'}]}, 'dist_params': {'backend': 'nccl'}, 'log_level': 'INFO', 'work_dir': './work_dirs', 'load_from': '/home/jinliang/epoch_9.pth', 'resume_from': None, 'workflow': [('train', 1)], 'SEED': 39189013, 'CUDNN_BENCHMARK': False, 'model_device': 'cuda', 'find_unused_parameters': True, 'config_file': 'configs/mcan/mcan_vqa.py', 'resume': False, 'eval_only': False, 'num_gpus': 4, 'num_machines': 2, 'machine_rank': 1, 'dist_url': 'tcp://100.2.95.103:8686', 'opts': []}
[11/19 20:12:01] MIX INFO: Running with full config:
Config (path: configs/mcan/mcan_vqa.py): {'model': {'type': 'MCAN', 'embedding': [{'type': 'WordEmbedding', 'vocab_file': '/home/jinliang/.cache/torch/mmf/data/datasets/textvqa/defaults/extras/vocabs/vocabulary_100k.txt', 'embedding_dim': 300}, {'type': 'TextEmbedding', 'emb_type': 'mcan', 'hidden_dim': 1024, 'embedding_dim': 300, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'num_attn_pool': 1, 'num_feat': 2}], 'encoder': {'type': 'ImageFeatureEncoder', 'encoder_type': 'default'}, 'backbone': {'type': 'TwoBranchEmbedding', 'embedding_dim': 2048, 'hidden_dim': 1024, 'cond_dim': 1024, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'cbn_num_layers': 4}, 'combine_model': {'type': 'BranchCombineLayer', 'img_dim': 1024, 'ques_dim': 1024}, 'head': {'type': 'ClassifierLayer', 'classifier_type': 'triple_linear', 'in_dim': 2048, 'out_dim': 3129}}, 'dataset_type': 'VQADATASET', 'data_root': '/home/jinliang/.cache/torch/mmf/', 'feature_path': 'data/datasets/vqa2/grid_features/features/', 'annotation_path': 'data/datasets/vqa2/grid_features/annotations/', 'vocab_path': 'data/datasets/vqa2/defaults/extras/vocabs/', 'train_datasets': ['train', 'val', 'visualgenome'], 'test_datasets': ['oneval'], 'vqa_reader_train_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val', 'visualgenome']}, 'vqa_reader_test_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler_cfg': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'train_data': {'samples_per_gpu': 4, 'workers_per_gpu': 1, 'sampler_name': 'TrainingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val', 'visualgenome']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'limit_nums': 400}}, 'test_data': {'samples_per_gpu': 4, 'workers_per_gpu': 1, 'sampler_name': 'TestingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}, 'eval_period': 50}, 'evaluator_type': 'VQA', 'optimizer': {'type': 'AdamW', 'lr': 5e-05, 'weight_decay': 0, 'eps': 1e-09, 'betas': [0.9, 0.98], 'training_encoder_lr_multiply': 1}, 'optimizer_config': {'grad_clip': None}, 'lr_config': {'use_warmup': True, 'lr_steps': [90000, 108000], 'lr_ratio': 0.2, 'warmup_factor': 0.25, 'warmup_iterations': 27000, 'policy': 'MultiStepScheduler'}, 'max_iter': 236000, 'by_iter': True, 'checkpoint_config': {'period': 5000}, 'log_config': {'period': 50, 'hooks': [{'type': 'TextLoggerHook'}]}, 'dist_params': {'backend': 'nccl'}, 'log_level': 'INFO', 'work_dir': './work_dirs', 'load_from': '/home/jinliang/epoch_9.pth', 'resume_from': None, 'workflow': [('train', 1)], 'SEED': 39189013, 'CUDNN_BENCHMARK': False, 'model_device': 'cuda', 'find_unused_parameters': True, 'config_file': 'configs/mcan/mcan_vqa.py', 'resume': False, 'eval_only': False, 'num_gpus': 4, 'num_machines': 2, 'machine_rank': 1, 'dist_url': 'tcp://100.2.95.103:8686', 'opts': []}
[11/19 20:12:27] MIX INFO: Organizer.init
[11/19 20:12:27] MIX INFO: Organizer.init
[11/19 20:18:26] MIX INFO: Rank of current process: 7. World size: 8
[11/19 20:18:26] MIX INFO: Rank of current process: 7. World size: 8
[11/19 20:18:26] MIX INFO: Environment info:
---------------------  ---------------------------------------------------------------------------------------
sys.platform           linux
Python                 3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 01:22:34) [GCC 7.3.0]
numpy                  1.18.5
detectron2             failed to import
detectron2._C          failed to import
Compiler               c++ (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)
CUDA compiler          Cuda compilation tools, release 10.1, V10.1.243
DETECTRON2_ENV_MODULE  <not set>
PyTorch                1.6.0+cu101 @/home/jinliang/miniconda3/envs/MIX/lib/python3.6/site-packages/torch
PyTorch debug build    False
GPU available          True
GPU 0,1,2,3            Tesla V100-PCIE-16GB
CUDA_HOME              /usr/local/cuda
Pillow                 6.2.2
torchvision            0.6.0+cu101 @/home/jinliang/miniconda3/envs/MIX/lib/python3.6/site-packages/torchvision
torchvision            unknown
cv2                    4.2.0
---------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF,

[11/19 20:18:26] MIX INFO: Environment info:
---------------------  ---------------------------------------------------------------------------------------
sys.platform           linux
Python                 3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 01:22:34) [GCC 7.3.0]
numpy                  1.18.5
detectron2             failed to import
detectron2._C          failed to import
Compiler               c++ (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)
CUDA compiler          Cuda compilation tools, release 10.1, V10.1.243
DETECTRON2_ENV_MODULE  <not set>
PyTorch                1.6.0+cu101 @/home/jinliang/miniconda3/envs/MIX/lib/python3.6/site-packages/torch
PyTorch debug build    False
GPU available          True
GPU 0,1,2,3            Tesla V100-PCIE-16GB
CUDA_HOME              /usr/local/cuda
Pillow                 6.2.2
torchvision            0.6.0+cu101 @/home/jinliang/miniconda3/envs/MIX/lib/python3.6/site-packages/torchvision
torchvision            unknown
cv2                    4.2.0
---------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF,

[11/19 20:18:26] MIX INFO: Command line arguments: Namespace(config_file='configs/mcan/mcan_vqa.py', dist_url='tcp://100.2.95.103:8686', eval_only=False, machine_rank=1, num_gpus=4, num_machines=2, opts=[], resume=False, work_dir=None)
[11/19 20:18:26] MIX INFO: Command line arguments: Namespace(config_file='configs/mcan/mcan_vqa.py', dist_url='tcp://100.2.95.103:8686', eval_only=False, machine_rank=1, num_gpus=4, num_machines=2, opts=[], resume=False, work_dir=None)
[11/19 20:18:26] MIX INFO: Contents of args.config_file=configs/mcan/mcan_vqa.py:
_base_ = [
    '../_base_/models/mcan_config.py',
    '../_base_/datasets/vqa_dataset.py',
    '../_base_/schedules/schedule_vqa.py',
    '../_base_/default_runtime.py'
] # yapf:disable

[11/19 20:18:26] MIX INFO: Contents of args.config_file=configs/mcan/mcan_vqa.py:
_base_ = [
    '../_base_/models/mcan_config.py',
    '../_base_/datasets/vqa_dataset.py',
    '../_base_/schedules/schedule_vqa.py',
    '../_base_/default_runtime.py'
] # yapf:disable

[11/19 20:18:26] MIX INFO: Running with full config:
Config (path: configs/mcan/mcan_vqa.py): {'model': {'type': 'MCAN', 'embedding': [{'type': 'WordEmbedding', 'vocab_file': '/home/jinliang/.cache/torch/mmf/data/datasets/textvqa/defaults/extras/vocabs/vocabulary_100k.txt', 'embedding_dim': 300}, {'type': 'TextEmbedding', 'emb_type': 'mcan', 'hidden_dim': 1024, 'embedding_dim': 300, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'num_attn_pool': 1, 'num_feat': 2}], 'encoder': {'type': 'ImageFeatureEncoder', 'encoder_type': 'default'}, 'backbone': {'type': 'TwoBranchEmbedding', 'embedding_dim': 2048, 'hidden_dim': 1024, 'cond_dim': 1024, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'cbn_num_layers': 4}, 'combine_model': {'type': 'BranchCombineLayer', 'img_dim': 1024, 'ques_dim': 1024}, 'head': {'type': 'ClassifierLayer', 'classifier_type': 'triple_linear', 'in_dim': 2048, 'out_dim': 3129}}, 'dataset_type': 'VQADATASET', 'data_root': '/home/jinliang/.cache/torch/mmf/', 'feature_path': 'data/datasets/vqa2/grid_features/features/', 'annotation_path': 'data/datasets/vqa2/grid_features/annotations/', 'vocab_path': 'data/datasets/vqa2/defaults/extras/vocabs/', 'train_datasets': ['train', 'val', 'visualgenome'], 'test_datasets': ['oneval'], 'vqa_reader_train_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val', 'visualgenome']}, 'vqa_reader_test_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler_cfg': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'train_data': {'samples_per_gpu': 4, 'workers_per_gpu': 1, 'sampler_name': 'TrainingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val', 'visualgenome']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'limit_nums': 400}}, 'test_data': {'samples_per_gpu': 4, 'workers_per_gpu': 1, 'sampler_name': 'TestingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}, 'eval_period': 5000}, 'evaluator_type': 'VQA', 'optimizer': {'type': 'AdamW', 'lr': 5e-05, 'weight_decay': 0, 'eps': 1e-09, 'betas': [0.9, 0.98], 'training_encoder_lr_multiply': 1}, 'optimizer_config': {'grad_clip': None}, 'lr_config': {'use_warmup': True, 'lr_steps': [90000, 108000], 'lr_ratio': 0.2, 'warmup_factor': 0.25, 'warmup_iterations': 27000, 'policy': 'MultiStepScheduler'}, 'max_iter': 236000, 'by_iter': True, 'checkpoint_config': {'period': 5000}, 'log_config': {'period': 50, 'hooks': [{'type': 'TextLoggerHook'}]}, 'dist_params': {'backend': 'nccl'}, 'log_level': 'INFO', 'work_dir': './work_dirs', 'load_from': '/home/jinliang/epoch_9.pth', 'resume_from': None, 'workflow': [('train', 1)], 'SEED': 39189013, 'CUDNN_BENCHMARK': False, 'model_device': 'cuda', 'find_unused_parameters': True, 'config_file': 'configs/mcan/mcan_vqa.py', 'resume': False, 'eval_only': False, 'num_gpus': 4, 'num_machines': 2, 'machine_rank': 1, 'dist_url': 'tcp://100.2.95.103:8686', 'opts': []}
[11/19 20:18:26] MIX INFO: Running with full config:
Config (path: configs/mcan/mcan_vqa.py): {'model': {'type': 'MCAN', 'embedding': [{'type': 'WordEmbedding', 'vocab_file': '/home/jinliang/.cache/torch/mmf/data/datasets/textvqa/defaults/extras/vocabs/vocabulary_100k.txt', 'embedding_dim': 300}, {'type': 'TextEmbedding', 'emb_type': 'mcan', 'hidden_dim': 1024, 'embedding_dim': 300, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'num_attn_pool': 1, 'num_feat': 2}], 'encoder': {'type': 'ImageFeatureEncoder', 'encoder_type': 'default'}, 'backbone': {'type': 'TwoBranchEmbedding', 'embedding_dim': 2048, 'hidden_dim': 1024, 'cond_dim': 1024, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'cbn_num_layers': 4}, 'combine_model': {'type': 'BranchCombineLayer', 'img_dim': 1024, 'ques_dim': 1024}, 'head': {'type': 'ClassifierLayer', 'classifier_type': 'triple_linear', 'in_dim': 2048, 'out_dim': 3129}}, 'dataset_type': 'VQADATASET', 'data_root': '/home/jinliang/.cache/torch/mmf/', 'feature_path': 'data/datasets/vqa2/grid_features/features/', 'annotation_path': 'data/datasets/vqa2/grid_features/annotations/', 'vocab_path': 'data/datasets/vqa2/defaults/extras/vocabs/', 'train_datasets': ['train', 'val', 'visualgenome'], 'test_datasets': ['oneval'], 'vqa_reader_train_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val', 'visualgenome']}, 'vqa_reader_test_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler_cfg': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'train_data': {'samples_per_gpu': 4, 'workers_per_gpu': 1, 'sampler_name': 'TrainingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val', 'visualgenome']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'limit_nums': 400}}, 'test_data': {'samples_per_gpu': 4, 'workers_per_gpu': 1, 'sampler_name': 'TestingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}, 'eval_period': 5000}, 'evaluator_type': 'VQA', 'optimizer': {'type': 'AdamW', 'lr': 5e-05, 'weight_decay': 0, 'eps': 1e-09, 'betas': [0.9, 0.98], 'training_encoder_lr_multiply': 1}, 'optimizer_config': {'grad_clip': None}, 'lr_config': {'use_warmup': True, 'lr_steps': [90000, 108000], 'lr_ratio': 0.2, 'warmup_factor': 0.25, 'warmup_iterations': 27000, 'policy': 'MultiStepScheduler'}, 'max_iter': 236000, 'by_iter': True, 'checkpoint_config': {'period': 5000}, 'log_config': {'period': 50, 'hooks': [{'type': 'TextLoggerHook'}]}, 'dist_params': {'backend': 'nccl'}, 'log_level': 'INFO', 'work_dir': './work_dirs', 'load_from': '/home/jinliang/epoch_9.pth', 'resume_from': None, 'workflow': [('train', 1)], 'SEED': 39189013, 'CUDNN_BENCHMARK': False, 'model_device': 'cuda', 'find_unused_parameters': True, 'config_file': 'configs/mcan/mcan_vqa.py', 'resume': False, 'eval_only': False, 'num_gpus': 4, 'num_machines': 2, 'machine_rank': 1, 'dist_url': 'tcp://100.2.95.103:8686', 'opts': []}
[11/19 20:18:51] MIX INFO: Organizer.init
[11/19 20:18:51] MIX INFO: Organizer.init
[11/19 20:24:12] MIX INFO: Rank of current process: 7. World size: 8
[11/19 20:24:12] MIX INFO: Rank of current process: 7. World size: 8
[11/19 20:24:12] MIX INFO: Environment info:
---------------------  ---------------------------------------------------------------------------------------
sys.platform           linux
Python                 3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 01:22:34) [GCC 7.3.0]
numpy                  1.18.5
detectron2             failed to import
detectron2._C          failed to import
Compiler               c++ (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)
CUDA compiler          Cuda compilation tools, release 10.1, V10.1.243
DETECTRON2_ENV_MODULE  <not set>
PyTorch                1.6.0+cu101 @/home/jinliang/miniconda3/envs/MIX/lib/python3.6/site-packages/torch
PyTorch debug build    False
GPU available          True
GPU 0,1,2,3            Tesla V100-PCIE-16GB
CUDA_HOME              /usr/local/cuda
Pillow                 6.2.2
torchvision            0.6.0+cu101 @/home/jinliang/miniconda3/envs/MIX/lib/python3.6/site-packages/torchvision
torchvision            unknown
cv2                    4.2.0
---------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF,

[11/19 20:24:12] MIX INFO: Environment info:
---------------------  ---------------------------------------------------------------------------------------
sys.platform           linux
Python                 3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 01:22:34) [GCC 7.3.0]
numpy                  1.18.5
detectron2             failed to import
detectron2._C          failed to import
Compiler               c++ (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)
CUDA compiler          Cuda compilation tools, release 10.1, V10.1.243
DETECTRON2_ENV_MODULE  <not set>
PyTorch                1.6.0+cu101 @/home/jinliang/miniconda3/envs/MIX/lib/python3.6/site-packages/torch
PyTorch debug build    False
GPU available          True
GPU 0,1,2,3            Tesla V100-PCIE-16GB
CUDA_HOME              /usr/local/cuda
Pillow                 6.2.2
torchvision            0.6.0+cu101 @/home/jinliang/miniconda3/envs/MIX/lib/python3.6/site-packages/torchvision
torchvision            unknown
cv2                    4.2.0
---------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF,

[11/19 20:24:12] MIX INFO: Command line arguments: Namespace(config_file='configs/mcan/mcan_vqa.py', dist_url='tcp://100.2.95.103:8686', eval_only=False, machine_rank=1, num_gpus=4, num_machines=2, opts=[], resume=False, work_dir=None)
[11/19 20:24:12] MIX INFO: Command line arguments: Namespace(config_file='configs/mcan/mcan_vqa.py', dist_url='tcp://100.2.95.103:8686', eval_only=False, machine_rank=1, num_gpus=4, num_machines=2, opts=[], resume=False, work_dir=None)
[11/19 20:24:12] MIX INFO: Contents of args.config_file=configs/mcan/mcan_vqa.py:
_base_ = [
    '../_base_/models/mcan_config.py',
    '../_base_/datasets/vqa_dataset.py',
    '../_base_/schedules/schedule_vqa.py',
    '../_base_/default_runtime.py'
] # yapf:disable

[11/19 20:24:12] MIX INFO: Contents of args.config_file=configs/mcan/mcan_vqa.py:
_base_ = [
    '../_base_/models/mcan_config.py',
    '../_base_/datasets/vqa_dataset.py',
    '../_base_/schedules/schedule_vqa.py',
    '../_base_/default_runtime.py'
] # yapf:disable

[11/19 20:24:12] MIX INFO: Running with full config:
Config (path: configs/mcan/mcan_vqa.py): {'model': {'type': 'MCAN', 'embedding': [{'type': 'WordEmbedding', 'vocab_file': '/home/jinliang/.cache/torch/mmf/data/datasets/textvqa/defaults/extras/vocabs/vocabulary_100k.txt', 'embedding_dim': 300}, {'type': 'TextEmbedding', 'emb_type': 'mcan', 'hidden_dim': 1024, 'embedding_dim': 300, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'num_attn_pool': 1, 'num_feat': 2}], 'encoder': {'type': 'ImageFeatureEncoder', 'encoder_type': 'default'}, 'backbone': {'type': 'TwoBranchEmbedding', 'embedding_dim': 2048, 'hidden_dim': 1024, 'cond_dim': 1024, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'cbn_num_layers': 4}, 'combine_model': {'type': 'BranchCombineLayer', 'img_dim': 1024, 'ques_dim': 1024}, 'head': {'type': 'ClassifierLayer', 'classifier_type': 'triple_linear', 'in_dim': 2048, 'out_dim': 3129}}, 'dataset_type': 'VQADATASET', 'data_root': '/home/jinliang/.cache/torch/mmf/', 'feature_path': 'data/datasets/vqa2/grid_features/features/', 'annotation_path': 'data/datasets/vqa2/grid_features/annotations/', 'vocab_path': 'data/datasets/vqa2/defaults/extras/vocabs/', 'train_datasets': ['train', 'val', 'visualgenome'], 'test_datasets': ['oneval'], 'vqa_reader_train_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val', 'visualgenome']}, 'vqa_reader_test_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler_cfg': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'train_data': {'samples_per_gpu': 4, 'workers_per_gpu': 1, 'sampler_name': 'TrainingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val', 'visualgenome']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'limit_nums': 400}}, 'test_data': {'samples_per_gpu': 4, 'workers_per_gpu': 1, 'sampler_name': 'TestingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}, 'eval_period': 5000}, 'evaluator_type': 'VQA', 'optimizer': {'type': 'AdamW', 'lr': 5e-05, 'weight_decay': 0, 'eps': 1e-09, 'betas': [0.9, 0.98], 'training_encoder_lr_multiply': 1}, 'optimizer_config': {'grad_clip': None}, 'lr_config': {'use_warmup': True, 'lr_steps': [90000, 108000], 'lr_ratio': 0.2, 'warmup_factor': 0.25, 'warmup_iterations': 27000, 'policy': 'MultiStepScheduler'}, 'max_iter': 236000, 'by_iter': True, 'checkpoint_config': {'period': 5000}, 'log_config': {'period': 5, 'hooks': [{'type': 'TextLoggerHook'}]}, 'dist_params': {'backend': 'nccl'}, 'log_level': 'INFO', 'work_dir': './work_dirs', 'load_from': '/home/jinliang/epoch_9.pth', 'resume_from': None, 'workflow': [('train', 1)], 'SEED': 39189013, 'CUDNN_BENCHMARK': False, 'model_device': 'cuda', 'find_unused_parameters': True, 'config_file': 'configs/mcan/mcan_vqa.py', 'resume': False, 'eval_only': False, 'num_gpus': 4, 'num_machines': 2, 'machine_rank': 1, 'dist_url': 'tcp://100.2.95.103:8686', 'opts': []}
[11/19 20:24:12] MIX INFO: Running with full config:
Config (path: configs/mcan/mcan_vqa.py): {'model': {'type': 'MCAN', 'embedding': [{'type': 'WordEmbedding', 'vocab_file': '/home/jinliang/.cache/torch/mmf/data/datasets/textvqa/defaults/extras/vocabs/vocabulary_100k.txt', 'embedding_dim': 300}, {'type': 'TextEmbedding', 'emb_type': 'mcan', 'hidden_dim': 1024, 'embedding_dim': 300, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'num_attn_pool': 1, 'num_feat': 2}], 'encoder': {'type': 'ImageFeatureEncoder', 'encoder_type': 'default'}, 'backbone': {'type': 'TwoBranchEmbedding', 'embedding_dim': 2048, 'hidden_dim': 1024, 'cond_dim': 1024, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'cbn_num_layers': 4}, 'combine_model': {'type': 'BranchCombineLayer', 'img_dim': 1024, 'ques_dim': 1024}, 'head': {'type': 'ClassifierLayer', 'classifier_type': 'triple_linear', 'in_dim': 2048, 'out_dim': 3129}}, 'dataset_type': 'VQADATASET', 'data_root': '/home/jinliang/.cache/torch/mmf/', 'feature_path': 'data/datasets/vqa2/grid_features/features/', 'annotation_path': 'data/datasets/vqa2/grid_features/annotations/', 'vocab_path': 'data/datasets/vqa2/defaults/extras/vocabs/', 'train_datasets': ['train', 'val', 'visualgenome'], 'test_datasets': ['oneval'], 'vqa_reader_train_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val', 'visualgenome']}, 'vqa_reader_test_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler_cfg': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'train_data': {'samples_per_gpu': 4, 'workers_per_gpu': 1, 'sampler_name': 'TrainingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val', 'visualgenome']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'limit_nums': 400}}, 'test_data': {'samples_per_gpu': 4, 'workers_per_gpu': 1, 'sampler_name': 'TestingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}, 'eval_period': 5000}, 'evaluator_type': 'VQA', 'optimizer': {'type': 'AdamW', 'lr': 5e-05, 'weight_decay': 0, 'eps': 1e-09, 'betas': [0.9, 0.98], 'training_encoder_lr_multiply': 1}, 'optimizer_config': {'grad_clip': None}, 'lr_config': {'use_warmup': True, 'lr_steps': [90000, 108000], 'lr_ratio': 0.2, 'warmup_factor': 0.25, 'warmup_iterations': 27000, 'policy': 'MultiStepScheduler'}, 'max_iter': 236000, 'by_iter': True, 'checkpoint_config': {'period': 5000}, 'log_config': {'period': 5, 'hooks': [{'type': 'TextLoggerHook'}]}, 'dist_params': {'backend': 'nccl'}, 'log_level': 'INFO', 'work_dir': './work_dirs', 'load_from': '/home/jinliang/epoch_9.pth', 'resume_from': None, 'workflow': [('train', 1)], 'SEED': 39189013, 'CUDNN_BENCHMARK': False, 'model_device': 'cuda', 'find_unused_parameters': True, 'config_file': 'configs/mcan/mcan_vqa.py', 'resume': False, 'eval_only': False, 'num_gpus': 4, 'num_machines': 2, 'machine_rank': 1, 'dist_url': 'tcp://100.2.95.103:8686', 'opts': []}
[11/19 20:24:38] MIX INFO: Organizer.init
[11/19 20:24:38] MIX INFO: Organizer.init
[11/20 16:03:53] MIX INFO: Rank of current process: 7. World size: 8
[11/20 16:03:53] MIX INFO: Rank of current process: 7. World size: 8
[11/20 16:03:54] MIX INFO: Environment info:
---------------------  ---------------------------------------------------------------------------------------
sys.platform           linux
Python                 3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 01:22:34) [GCC 7.3.0]
numpy                  1.18.5
detectron2             failed to import
detectron2._C          failed to import
Compiler               c++ (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)
CUDA compiler          Cuda compilation tools, release 10.1, V10.1.243
DETECTRON2_ENV_MODULE  <not set>
PyTorch                1.6.0+cu101 @/home/jinliang/miniconda3/envs/MIX/lib/python3.6/site-packages/torch
PyTorch debug build    False
GPU available          True
GPU 0,1,2,3            Tesla V100-PCIE-16GB
CUDA_HOME              /usr/local/cuda
Pillow                 6.2.2
torchvision            0.6.0+cu101 @/home/jinliang/miniconda3/envs/MIX/lib/python3.6/site-packages/torchvision
torchvision            unknown
cv2                    4.2.0
---------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF,

[11/20 16:03:54] MIX INFO: Environment info:
---------------------  ---------------------------------------------------------------------------------------
sys.platform           linux
Python                 3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 01:22:34) [GCC 7.3.0]
numpy                  1.18.5
detectron2             failed to import
detectron2._C          failed to import
Compiler               c++ (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)
CUDA compiler          Cuda compilation tools, release 10.1, V10.1.243
DETECTRON2_ENV_MODULE  <not set>
PyTorch                1.6.0+cu101 @/home/jinliang/miniconda3/envs/MIX/lib/python3.6/site-packages/torch
PyTorch debug build    False
GPU available          True
GPU 0,1,2,3            Tesla V100-PCIE-16GB
CUDA_HOME              /usr/local/cuda
Pillow                 6.2.2
torchvision            0.6.0+cu101 @/home/jinliang/miniconda3/envs/MIX/lib/python3.6/site-packages/torchvision
torchvision            unknown
cv2                    4.2.0
---------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF,

[11/20 16:03:54] MIX INFO: Command line arguments: Namespace(config_file='configs/mcan/mcan_vqa.py', dist_url='tcp://192.168.3.103:8686', eval_only=False, machine_rank=1, num_gpus=4, num_machines=2, opts=[], resume=False, work_dir='work_dirs/')
[11/20 16:03:54] MIX INFO: Command line arguments: Namespace(config_file='configs/mcan/mcan_vqa.py', dist_url='tcp://192.168.3.103:8686', eval_only=False, machine_rank=1, num_gpus=4, num_machines=2, opts=[], resume=False, work_dir='work_dirs/')
[11/20 16:03:54] MIX INFO: Contents of args.config_file=configs/mcan/mcan_vqa.py:
_base_ = [
    '../_base_/models/mcan_config.py',
    '../_base_/datasets/vqa_dataset.py',
    '../_base_/schedules/schedule_vqa.py',
    '../_base_/default_runtime.py'
] # yapf:disable

[11/20 16:03:54] MIX INFO: Contents of args.config_file=configs/mcan/mcan_vqa.py:
_base_ = [
    '../_base_/models/mcan_config.py',
    '../_base_/datasets/vqa_dataset.py',
    '../_base_/schedules/schedule_vqa.py',
    '../_base_/default_runtime.py'
] # yapf:disable

[11/20 16:03:54] MIX INFO: Running with full config:
Config (path: configs/mcan/mcan_vqa.py): {'model': {'type': 'MCAN', 'embedding': [{'type': 'WordEmbedding', 'vocab_file': '/home/jinliang/.cache/torch/mmf/data/datasets/textvqa/defaults/extras/vocabs/vocabulary_100k.txt', 'embedding_dim': 300}, {'type': 'TextEmbedding', 'emb_type': 'mcan', 'hidden_dim': 1024, 'embedding_dim': 300, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'num_attn_pool': 1, 'num_feat': 2}], 'encoder': {'type': 'ImageFeatureEncoder', 'encoder_type': 'default'}, 'backbone': {'type': 'TwoBranchEmbedding', 'embedding_dim': 2048, 'hidden_dim': 1024, 'cond_dim': 1024, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'cbn_num_layers': 4}, 'combine_model': {'type': 'BranchCombineLayer', 'img_dim': 1024, 'ques_dim': 1024}, 'head': {'type': 'ClassifierLayer', 'classifier_type': 'triple_linear', 'in_dim': 2048, 'out_dim': 3129}}, 'dataset_type': 'VQADATASET', 'data_root': '/home/jinliang/.cache/torch/mmf/', 'feature_path': 'data/datasets/vqa2/grid_features/features/', 'annotation_path': 'data/datasets/vqa2/grid_features/annotations/', 'vocab_path': 'data/datasets/vqa2/defaults/extras/vocabs/', 'train_datasets': ['visualgenome'], 'test_datasets': ['oneval'], 'vqa_reader_train_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['visualgenome']}, 'vqa_reader_test_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler_cfg': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'train_data': {'samples_per_gpu': 4, 'workers_per_gpu': 1, 'sampler_name': 'TrainingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['visualgenome']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}}, 'test_data': {'samples_per_gpu': 4, 'workers_per_gpu': 1, 'sampler_name': 'TestingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}, 'eval_period': 5000}, 'evaluator_type': 'VQA', 'optimizer': {'type': 'AdamW', 'lr': 5e-05, 'weight_decay': 0, 'eps': 1e-09, 'betas': [0.9, 0.98], 'training_encoder_lr_multiply': 1}, 'optimizer_config': {'grad_clip': None}, 'lr_config': {'use_warmup': True, 'lr_steps': [90000, 108000], 'lr_ratio': 0.2, 'warmup_factor': 0.25, 'warmup_iterations': 27000, 'policy': 'MultiStepScheduler'}, 'max_iter': 236000, 'by_iter': True, 'checkpoint_config': {'period': 5000}, 'log_config': {'period': 50, 'hooks': [{'type': 'TextLoggerHook'}]}, 'dist_params': {'backend': 'nccl'}, 'log_level': 'INFO', 'work_dir': 'work_dirs/', 'load_from': None, 'resume_from': None, 'workflow': [('train', 1)], 'SEED': 39189013, 'CUDNN_BENCHMARK': False, 'model_device': 'cuda', 'find_unused_parameters': True, 'config_file': 'configs/mcan/mcan_vqa.py', 'resume': False, 'eval_only': False, 'num_gpus': 4, 'num_machines': 2, 'machine_rank': 1, 'dist_url': 'tcp://192.168.3.103:8686', 'opts': []}
[11/20 16:03:54] MIX INFO: Running with full config:
Config (path: configs/mcan/mcan_vqa.py): {'model': {'type': 'MCAN', 'embedding': [{'type': 'WordEmbedding', 'vocab_file': '/home/jinliang/.cache/torch/mmf/data/datasets/textvqa/defaults/extras/vocabs/vocabulary_100k.txt', 'embedding_dim': 300}, {'type': 'TextEmbedding', 'emb_type': 'mcan', 'hidden_dim': 1024, 'embedding_dim': 300, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'num_attn_pool': 1, 'num_feat': 2}], 'encoder': {'type': 'ImageFeatureEncoder', 'encoder_type': 'default'}, 'backbone': {'type': 'TwoBranchEmbedding', 'embedding_dim': 2048, 'hidden_dim': 1024, 'cond_dim': 1024, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'cbn_num_layers': 4}, 'combine_model': {'type': 'BranchCombineLayer', 'img_dim': 1024, 'ques_dim': 1024}, 'head': {'type': 'ClassifierLayer', 'classifier_type': 'triple_linear', 'in_dim': 2048, 'out_dim': 3129}}, 'dataset_type': 'VQADATASET', 'data_root': '/home/jinliang/.cache/torch/mmf/', 'feature_path': 'data/datasets/vqa2/grid_features/features/', 'annotation_path': 'data/datasets/vqa2/grid_features/annotations/', 'vocab_path': 'data/datasets/vqa2/defaults/extras/vocabs/', 'train_datasets': ['visualgenome'], 'test_datasets': ['oneval'], 'vqa_reader_train_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['visualgenome']}, 'vqa_reader_test_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler_cfg': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'train_data': {'samples_per_gpu': 4, 'workers_per_gpu': 1, 'sampler_name': 'TrainingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['visualgenome']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}}, 'test_data': {'samples_per_gpu': 4, 'workers_per_gpu': 1, 'sampler_name': 'TestingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}, 'eval_period': 5000}, 'evaluator_type': 'VQA', 'optimizer': {'type': 'AdamW', 'lr': 5e-05, 'weight_decay': 0, 'eps': 1e-09, 'betas': [0.9, 0.98], 'training_encoder_lr_multiply': 1}, 'optimizer_config': {'grad_clip': None}, 'lr_config': {'use_warmup': True, 'lr_steps': [90000, 108000], 'lr_ratio': 0.2, 'warmup_factor': 0.25, 'warmup_iterations': 27000, 'policy': 'MultiStepScheduler'}, 'max_iter': 236000, 'by_iter': True, 'checkpoint_config': {'period': 5000}, 'log_config': {'period': 50, 'hooks': [{'type': 'TextLoggerHook'}]}, 'dist_params': {'backend': 'nccl'}, 'log_level': 'INFO', 'work_dir': 'work_dirs/', 'load_from': None, 'resume_from': None, 'workflow': [('train', 1)], 'SEED': 39189013, 'CUDNN_BENCHMARK': False, 'model_device': 'cuda', 'find_unused_parameters': True, 'config_file': 'configs/mcan/mcan_vqa.py', 'resume': False, 'eval_only': False, 'num_gpus': 4, 'num_machines': 2, 'machine_rank': 1, 'dist_url': 'tcp://192.168.3.103:8686', 'opts': []}
[11/20 16:04:03] MIX INFO: Organizer.init
[11/20 16:04:03] MIX INFO: Organizer.init
[11/20 16:07:35] MIX INFO: Rank of current process: 7. World size: 8
[11/20 16:07:35] MIX INFO: Rank of current process: 7. World size: 8
[11/20 16:07:36] MIX INFO: Environment info:
---------------------  ---------------------------------------------------------------------------------------
sys.platform           linux
Python                 3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 01:22:34) [GCC 7.3.0]
numpy                  1.18.5
detectron2             failed to import
detectron2._C          failed to import
Compiler               c++ (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)
CUDA compiler          Cuda compilation tools, release 10.1, V10.1.243
DETECTRON2_ENV_MODULE  <not set>
PyTorch                1.6.0+cu101 @/home/jinliang/miniconda3/envs/MIX/lib/python3.6/site-packages/torch
PyTorch debug build    False
GPU available          True
GPU 0,1,2,3            Tesla V100-PCIE-16GB
CUDA_HOME              /usr/local/cuda
Pillow                 6.2.2
torchvision            0.6.0+cu101 @/home/jinliang/miniconda3/envs/MIX/lib/python3.6/site-packages/torchvision
torchvision            unknown
cv2                    4.2.0
---------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF,

[11/20 16:07:36] MIX INFO: Environment info:
---------------------  ---------------------------------------------------------------------------------------
sys.platform           linux
Python                 3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 01:22:34) [GCC 7.3.0]
numpy                  1.18.5
detectron2             failed to import
detectron2._C          failed to import
Compiler               c++ (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)
CUDA compiler          Cuda compilation tools, release 10.1, V10.1.243
DETECTRON2_ENV_MODULE  <not set>
PyTorch                1.6.0+cu101 @/home/jinliang/miniconda3/envs/MIX/lib/python3.6/site-packages/torch
PyTorch debug build    False
GPU available          True
GPU 0,1,2,3            Tesla V100-PCIE-16GB
CUDA_HOME              /usr/local/cuda
Pillow                 6.2.2
torchvision            0.6.0+cu101 @/home/jinliang/miniconda3/envs/MIX/lib/python3.6/site-packages/torchvision
torchvision            unknown
cv2                    4.2.0
---------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF,

[11/20 16:07:36] MIX INFO: Command line arguments: Namespace(config_file='configs/mcan/mcan_vqa.py', dist_url='tcp://192.168.3.103:8686', eval_only=False, machine_rank=1, num_gpus=4, num_machines=2, opts=[], resume=False, work_dir='work_dirs/')
[11/20 16:07:36] MIX INFO: Command line arguments: Namespace(config_file='configs/mcan/mcan_vqa.py', dist_url='tcp://192.168.3.103:8686', eval_only=False, machine_rank=1, num_gpus=4, num_machines=2, opts=[], resume=False, work_dir='work_dirs/')
[11/20 16:07:36] MIX INFO: Contents of args.config_file=configs/mcan/mcan_vqa.py:
_base_ = [
    '../_base_/models/mcan_config.py',
    '../_base_/datasets/vqa_dataset.py',
    '../_base_/schedules/schedule_vqa.py',
    '../_base_/default_runtime.py'
] # yapf:disable

[11/20 16:07:36] MIX INFO: Contents of args.config_file=configs/mcan/mcan_vqa.py:
_base_ = [
    '../_base_/models/mcan_config.py',
    '../_base_/datasets/vqa_dataset.py',
    '../_base_/schedules/schedule_vqa.py',
    '../_base_/default_runtime.py'
] # yapf:disable

[11/20 16:07:36] MIX INFO: Running with full config:
Config (path: configs/mcan/mcan_vqa.py): {'model': {'type': 'MCAN', 'embedding': [{'type': 'WordEmbedding', 'vocab_file': '/home/jinliang/.cache/torch/mmf/data/datasets/textvqa/defaults/extras/vocabs/vocabulary_100k.txt', 'embedding_dim': 300}, {'type': 'TextEmbedding', 'emb_type': 'mcan', 'hidden_dim': 1024, 'embedding_dim': 300, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'num_attn_pool': 1, 'num_feat': 2}], 'encoder': {'type': 'ImageFeatureEncoder', 'encoder_type': 'default'}, 'backbone': {'type': 'TwoBranchEmbedding', 'embedding_dim': 2048, 'hidden_dim': 1024, 'cond_dim': 1024, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'cbn_num_layers': 4}, 'combine_model': {'type': 'BranchCombineLayer', 'img_dim': 1024, 'ques_dim': 1024}, 'head': {'type': 'ClassifierLayer', 'classifier_type': 'triple_linear', 'in_dim': 2048, 'out_dim': 3129}}, 'dataset_type': 'VQADATASET', 'data_root': '/home/jinliang/.cache/torch/mmf/', 'feature_path': 'data/datasets/vqa2/grid_features/features/', 'annotation_path': 'data/datasets/vqa2/grid_features/annotations/', 'vocab_path': 'data/datasets/vqa2/defaults/extras/vocabs/', 'train_datasets': ['train', 'val'], 'test_datasets': ['oneval'], 'vqa_reader_train_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val']}, 'vqa_reader_test_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler_cfg': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'train_data': {'samples_per_gpu': 4, 'workers_per_gpu': 1, 'sampler_name': 'TrainingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}}, 'test_data': {'samples_per_gpu': 4, 'workers_per_gpu': 1, 'sampler_name': 'TestingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}, 'eval_period': 5000}, 'evaluator_type': 'VQA', 'optimizer': {'type': 'AdamW', 'lr': 5e-05, 'weight_decay': 0, 'eps': 1e-09, 'betas': [0.9, 0.98], 'training_encoder_lr_multiply': 1}, 'optimizer_config': {'grad_clip': None}, 'lr_config': {'use_warmup': True, 'lr_steps': [90000, 108000], 'lr_ratio': 0.2, 'warmup_factor': 0.25, 'warmup_iterations': 27000, 'policy': 'MultiStepScheduler'}, 'max_iter': 236000, 'by_iter': True, 'checkpoint_config': {'period': 5000}, 'log_config': {'period': 50, 'hooks': [{'type': 'TextLoggerHook'}]}, 'dist_params': {'backend': 'nccl'}, 'log_level': 'INFO', 'work_dir': 'work_dirs/', 'load_from': None, 'resume_from': None, 'workflow': [('train', 1)], 'SEED': 39189013, 'CUDNN_BENCHMARK': False, 'model_device': 'cuda', 'find_unused_parameters': True, 'config_file': 'configs/mcan/mcan_vqa.py', 'resume': False, 'eval_only': False, 'num_gpus': 4, 'num_machines': 2, 'machine_rank': 1, 'dist_url': 'tcp://192.168.3.103:8686', 'opts': []}
[11/20 16:07:36] MIX INFO: Running with full config:
Config (path: configs/mcan/mcan_vqa.py): {'model': {'type': 'MCAN', 'embedding': [{'type': 'WordEmbedding', 'vocab_file': '/home/jinliang/.cache/torch/mmf/data/datasets/textvqa/defaults/extras/vocabs/vocabulary_100k.txt', 'embedding_dim': 300}, {'type': 'TextEmbedding', 'emb_type': 'mcan', 'hidden_dim': 1024, 'embedding_dim': 300, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'num_attn_pool': 1, 'num_feat': 2}], 'encoder': {'type': 'ImageFeatureEncoder', 'encoder_type': 'default'}, 'backbone': {'type': 'TwoBranchEmbedding', 'embedding_dim': 2048, 'hidden_dim': 1024, 'cond_dim': 1024, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'cbn_num_layers': 4}, 'combine_model': {'type': 'BranchCombineLayer', 'img_dim': 1024, 'ques_dim': 1024}, 'head': {'type': 'ClassifierLayer', 'classifier_type': 'triple_linear', 'in_dim': 2048, 'out_dim': 3129}}, 'dataset_type': 'VQADATASET', 'data_root': '/home/jinliang/.cache/torch/mmf/', 'feature_path': 'data/datasets/vqa2/grid_features/features/', 'annotation_path': 'data/datasets/vqa2/grid_features/annotations/', 'vocab_path': 'data/datasets/vqa2/defaults/extras/vocabs/', 'train_datasets': ['train', 'val'], 'test_datasets': ['oneval'], 'vqa_reader_train_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val']}, 'vqa_reader_test_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler_cfg': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'train_data': {'samples_per_gpu': 4, 'workers_per_gpu': 1, 'sampler_name': 'TrainingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}}, 'test_data': {'samples_per_gpu': 4, 'workers_per_gpu': 1, 'sampler_name': 'TestingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}, 'eval_period': 5000}, 'evaluator_type': 'VQA', 'optimizer': {'type': 'AdamW', 'lr': 5e-05, 'weight_decay': 0, 'eps': 1e-09, 'betas': [0.9, 0.98], 'training_encoder_lr_multiply': 1}, 'optimizer_config': {'grad_clip': None}, 'lr_config': {'use_warmup': True, 'lr_steps': [90000, 108000], 'lr_ratio': 0.2, 'warmup_factor': 0.25, 'warmup_iterations': 27000, 'policy': 'MultiStepScheduler'}, 'max_iter': 236000, 'by_iter': True, 'checkpoint_config': {'period': 5000}, 'log_config': {'period': 50, 'hooks': [{'type': 'TextLoggerHook'}]}, 'dist_params': {'backend': 'nccl'}, 'log_level': 'INFO', 'work_dir': 'work_dirs/', 'load_from': None, 'resume_from': None, 'workflow': [('train', 1)], 'SEED': 39189013, 'CUDNN_BENCHMARK': False, 'model_device': 'cuda', 'find_unused_parameters': True, 'config_file': 'configs/mcan/mcan_vqa.py', 'resume': False, 'eval_only': False, 'num_gpus': 4, 'num_machines': 2, 'machine_rank': 1, 'dist_url': 'tcp://192.168.3.103:8686', 'opts': []}
[11/20 16:07:47] MIX INFO: Organizer.init
[11/20 16:07:47] MIX INFO: Organizer.init
[11/20 16:13:27] MIX INFO: Rank of current process: 7. World size: 8
[11/20 16:13:27] MIX INFO: Rank of current process: 7. World size: 8
[11/20 16:13:27] MIX INFO: Environment info:
---------------------  ---------------------------------------------------------------------------------------
sys.platform           linux
Python                 3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 01:22:34) [GCC 7.3.0]
numpy                  1.18.5
detectron2             failed to import
detectron2._C          failed to import
Compiler               c++ (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)
CUDA compiler          Cuda compilation tools, release 10.1, V10.1.243
DETECTRON2_ENV_MODULE  <not set>
PyTorch                1.6.0+cu101 @/home/jinliang/miniconda3/envs/MIX/lib/python3.6/site-packages/torch
PyTorch debug build    False
GPU available          True
GPU 0,1,2,3            Tesla V100-PCIE-16GB
CUDA_HOME              /usr/local/cuda
Pillow                 6.2.2
torchvision            0.6.0+cu101 @/home/jinliang/miniconda3/envs/MIX/lib/python3.6/site-packages/torchvision
torchvision            unknown
cv2                    4.2.0
---------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF,

[11/20 16:13:27] MIX INFO: Environment info:
---------------------  ---------------------------------------------------------------------------------------
sys.platform           linux
Python                 3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 01:22:34) [GCC 7.3.0]
numpy                  1.18.5
detectron2             failed to import
detectron2._C          failed to import
Compiler               c++ (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)
CUDA compiler          Cuda compilation tools, release 10.1, V10.1.243
DETECTRON2_ENV_MODULE  <not set>
PyTorch                1.6.0+cu101 @/home/jinliang/miniconda3/envs/MIX/lib/python3.6/site-packages/torch
PyTorch debug build    False
GPU available          True
GPU 0,1,2,3            Tesla V100-PCIE-16GB
CUDA_HOME              /usr/local/cuda
Pillow                 6.2.2
torchvision            0.6.0+cu101 @/home/jinliang/miniconda3/envs/MIX/lib/python3.6/site-packages/torchvision
torchvision            unknown
cv2                    4.2.0
---------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF,

[11/20 16:13:27] MIX INFO: Command line arguments: Namespace(config_file='configs/mcan/mcan_vqa.py', dist_url='tcp://192.168.3.103:8686', eval_only=False, machine_rank=1, num_gpus=4, num_machines=2, opts=[], resume=False, work_dir='work_dirs/')
[11/20 16:13:27] MIX INFO: Command line arguments: Namespace(config_file='configs/mcan/mcan_vqa.py', dist_url='tcp://192.168.3.103:8686', eval_only=False, machine_rank=1, num_gpus=4, num_machines=2, opts=[], resume=False, work_dir='work_dirs/')
[11/20 16:13:27] MIX INFO: Contents of args.config_file=configs/mcan/mcan_vqa.py:
_base_ = [
    '../_base_/models/mcan_config.py',
    '../_base_/datasets/vqa_dataset.py',
    '../_base_/schedules/schedule_vqa.py',
    '../_base_/default_runtime.py'
] # yapf:disable

[11/20 16:13:27] MIX INFO: Contents of args.config_file=configs/mcan/mcan_vqa.py:
_base_ = [
    '../_base_/models/mcan_config.py',
    '../_base_/datasets/vqa_dataset.py',
    '../_base_/schedules/schedule_vqa.py',
    '../_base_/default_runtime.py'
] # yapf:disable

[11/20 16:13:27] MIX INFO: Running with full config:
Config (path: configs/mcan/mcan_vqa.py): {'model': {'type': 'MCAN', 'embedding': [{'type': 'WordEmbedding', 'vocab_file': '/home/jinliang/.cache/torch/mmf/data/datasets/textvqa/defaults/extras/vocabs/vocabulary_100k.txt', 'embedding_dim': 300}, {'type': 'TextEmbedding', 'emb_type': 'mcan', 'hidden_dim': 1024, 'embedding_dim': 300, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'num_attn_pool': 1, 'num_feat': 2}], 'encoder': {'type': 'ImageFeatureEncoder', 'encoder_type': 'default'}, 'backbone': {'type': 'TwoBranchEmbedding', 'embedding_dim': 2048, 'hidden_dim': 1024, 'cond_dim': 1024, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'cbn_num_layers': 4}, 'combine_model': {'type': 'BranchCombineLayer', 'img_dim': 1024, 'ques_dim': 1024}, 'head': {'type': 'ClassifierLayer', 'classifier_type': 'triple_linear', 'in_dim': 2048, 'out_dim': 3129}}, 'dataset_type': 'VQADATASET', 'data_root': '/home/jinliang/.cache/torch/mmf/', 'feature_path': 'data/datasets/vqa2/grid_features/features/', 'annotation_path': 'data/datasets/vqa2/grid_features/annotations/', 'vocab_path': 'data/datasets/vqa2/defaults/extras/vocabs/', 'train_datasets': ['train'], 'test_datasets': ['oneval'], 'vqa_reader_train_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train']}, 'vqa_reader_test_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler_cfg': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'train_data': {'samples_per_gpu': 4, 'workers_per_gpu': 1, 'sampler_name': 'TrainingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}}, 'test_data': {'samples_per_gpu': 4, 'workers_per_gpu': 1, 'sampler_name': 'TestingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}, 'eval_period': 5000}, 'evaluator_type': 'VQA', 'optimizer': {'type': 'AdamW', 'lr': 5e-05, 'weight_decay': 0, 'eps': 1e-09, 'betas': [0.9, 0.98], 'training_encoder_lr_multiply': 1}, 'optimizer_config': {'grad_clip': None}, 'lr_config': {'use_warmup': True, 'lr_steps': [90000, 108000], 'lr_ratio': 0.2, 'warmup_factor': 0.25, 'warmup_iterations': 27000, 'policy': 'MultiStepScheduler'}, 'max_iter': 236000, 'by_iter': True, 'checkpoint_config': {'period': 5000}, 'log_config': {'period': 50, 'hooks': [{'type': 'TextLoggerHook'}]}, 'dist_params': {'backend': 'nccl'}, 'log_level': 'INFO', 'work_dir': 'work_dirs/', 'load_from': None, 'resume_from': None, 'workflow': [('train', 1)], 'SEED': 39189013, 'CUDNN_BENCHMARK': False, 'model_device': 'cuda', 'find_unused_parameters': True, 'config_file': 'configs/mcan/mcan_vqa.py', 'resume': False, 'eval_only': False, 'num_gpus': 4, 'num_machines': 2, 'machine_rank': 1, 'dist_url': 'tcp://192.168.3.103:8686', 'opts': []}
[11/20 16:13:27] MIX INFO: Running with full config:
Config (path: configs/mcan/mcan_vqa.py): {'model': {'type': 'MCAN', 'embedding': [{'type': 'WordEmbedding', 'vocab_file': '/home/jinliang/.cache/torch/mmf/data/datasets/textvqa/defaults/extras/vocabs/vocabulary_100k.txt', 'embedding_dim': 300}, {'type': 'TextEmbedding', 'emb_type': 'mcan', 'hidden_dim': 1024, 'embedding_dim': 300, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'num_attn_pool': 1, 'num_feat': 2}], 'encoder': {'type': 'ImageFeatureEncoder', 'encoder_type': 'default'}, 'backbone': {'type': 'TwoBranchEmbedding', 'embedding_dim': 2048, 'hidden_dim': 1024, 'cond_dim': 1024, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'cbn_num_layers': 4}, 'combine_model': {'type': 'BranchCombineLayer', 'img_dim': 1024, 'ques_dim': 1024}, 'head': {'type': 'ClassifierLayer', 'classifier_type': 'triple_linear', 'in_dim': 2048, 'out_dim': 3129}}, 'dataset_type': 'VQADATASET', 'data_root': '/home/jinliang/.cache/torch/mmf/', 'feature_path': 'data/datasets/vqa2/grid_features/features/', 'annotation_path': 'data/datasets/vqa2/grid_features/annotations/', 'vocab_path': 'data/datasets/vqa2/defaults/extras/vocabs/', 'train_datasets': ['train'], 'test_datasets': ['oneval'], 'vqa_reader_train_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train']}, 'vqa_reader_test_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler_cfg': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'train_data': {'samples_per_gpu': 4, 'workers_per_gpu': 1, 'sampler_name': 'TrainingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}}, 'test_data': {'samples_per_gpu': 4, 'workers_per_gpu': 1, 'sampler_name': 'TestingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}, 'eval_period': 5000}, 'evaluator_type': 'VQA', 'optimizer': {'type': 'AdamW', 'lr': 5e-05, 'weight_decay': 0, 'eps': 1e-09, 'betas': [0.9, 0.98], 'training_encoder_lr_multiply': 1}, 'optimizer_config': {'grad_clip': None}, 'lr_config': {'use_warmup': True, 'lr_steps': [90000, 108000], 'lr_ratio': 0.2, 'warmup_factor': 0.25, 'warmup_iterations': 27000, 'policy': 'MultiStepScheduler'}, 'max_iter': 236000, 'by_iter': True, 'checkpoint_config': {'period': 5000}, 'log_config': {'period': 50, 'hooks': [{'type': 'TextLoggerHook'}]}, 'dist_params': {'backend': 'nccl'}, 'log_level': 'INFO', 'work_dir': 'work_dirs/', 'load_from': None, 'resume_from': None, 'workflow': [('train', 1)], 'SEED': 39189013, 'CUDNN_BENCHMARK': False, 'model_device': 'cuda', 'find_unused_parameters': True, 'config_file': 'configs/mcan/mcan_vqa.py', 'resume': False, 'eval_only': False, 'num_gpus': 4, 'num_machines': 2, 'machine_rank': 1, 'dist_url': 'tcp://192.168.3.103:8686', 'opts': []}
[11/20 16:13:36] MIX INFO: Organizer.init
[11/20 16:13:36] MIX INFO: Organizer.init
[11/20 16:16:22] MIX INFO: Rank of current process: 7. World size: 8
[11/20 16:16:22] MIX INFO: Rank of current process: 7. World size: 8
[11/20 16:16:23] MIX INFO: Environment info:
---------------------  ---------------------------------------------------------------------------------------
sys.platform           linux
Python                 3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 01:22:34) [GCC 7.3.0]
numpy                  1.18.5
detectron2             failed to import
detectron2._C          failed to import
Compiler               c++ (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)
CUDA compiler          Cuda compilation tools, release 10.1, V10.1.243
DETECTRON2_ENV_MODULE  <not set>
PyTorch                1.6.0+cu101 @/home/jinliang/miniconda3/envs/MIX/lib/python3.6/site-packages/torch
PyTorch debug build    False
GPU available          True
GPU 0,1,2,3            Tesla V100-PCIE-16GB
CUDA_HOME              /usr/local/cuda
Pillow                 6.2.2
torchvision            0.6.0+cu101 @/home/jinliang/miniconda3/envs/MIX/lib/python3.6/site-packages/torchvision
torchvision            unknown
cv2                    4.2.0
---------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF,

[11/20 16:16:23] MIX INFO: Environment info:
---------------------  ---------------------------------------------------------------------------------------
sys.platform           linux
Python                 3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 01:22:34) [GCC 7.3.0]
numpy                  1.18.5
detectron2             failed to import
detectron2._C          failed to import
Compiler               c++ (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)
CUDA compiler          Cuda compilation tools, release 10.1, V10.1.243
DETECTRON2_ENV_MODULE  <not set>
PyTorch                1.6.0+cu101 @/home/jinliang/miniconda3/envs/MIX/lib/python3.6/site-packages/torch
PyTorch debug build    False
GPU available          True
GPU 0,1,2,3            Tesla V100-PCIE-16GB
CUDA_HOME              /usr/local/cuda
Pillow                 6.2.2
torchvision            0.6.0+cu101 @/home/jinliang/miniconda3/envs/MIX/lib/python3.6/site-packages/torchvision
torchvision            unknown
cv2                    4.2.0
---------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF,

[11/20 16:16:23] MIX INFO: Command line arguments: Namespace(config_file='configs/mcan/mcan_vqa.py', dist_url='tcp://192.168.3.103:8686', eval_only=False, machine_rank=1, num_gpus=4, num_machines=2, opts=[], resume=False, work_dir='work_dirs/')
[11/20 16:16:23] MIX INFO: Command line arguments: Namespace(config_file='configs/mcan/mcan_vqa.py', dist_url='tcp://192.168.3.103:8686', eval_only=False, machine_rank=1, num_gpus=4, num_machines=2, opts=[], resume=False, work_dir='work_dirs/')
[11/20 16:16:23] MIX INFO: Contents of args.config_file=configs/mcan/mcan_vqa.py:
_base_ = [
    '../_base_/models/mcan_config.py',
    '../_base_/datasets/vqa_dataset.py',
    '../_base_/schedules/schedule_vqa.py',
    '../_base_/default_runtime.py'
] # yapf:disable

[11/20 16:16:23] MIX INFO: Contents of args.config_file=configs/mcan/mcan_vqa.py:
_base_ = [
    '../_base_/models/mcan_config.py',
    '../_base_/datasets/vqa_dataset.py',
    '../_base_/schedules/schedule_vqa.py',
    '../_base_/default_runtime.py'
] # yapf:disable

[11/20 16:16:23] MIX INFO: Running with full config:
Config (path: configs/mcan/mcan_vqa.py): {'model': {'type': 'MCAN', 'embedding': [{'type': 'WordEmbedding', 'vocab_file': '/home/jinliang/.cache/torch/mmf/data/datasets/textvqa/defaults/extras/vocabs/vocabulary_100k.txt', 'embedding_dim': 300}, {'type': 'TextEmbedding', 'emb_type': 'mcan', 'hidden_dim': 1024, 'embedding_dim': 300, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'num_attn_pool': 1, 'num_feat': 2}], 'encoder': {'type': 'ImageFeatureEncoder', 'encoder_type': 'default'}, 'backbone': {'type': 'TwoBranchEmbedding', 'embedding_dim': 2048, 'hidden_dim': 1024, 'cond_dim': 1024, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'cbn_num_layers': 4}, 'combine_model': {'type': 'BranchCombineLayer', 'img_dim': 1024, 'ques_dim': 1024}, 'head': {'type': 'ClassifierLayer', 'classifier_type': 'triple_linear', 'in_dim': 2048, 'out_dim': 3129}}, 'dataset_type': 'VQADATASET', 'data_root': '/home/jinliang/.cache/torch/mmf/', 'feature_path': 'data/datasets/vqa2/grid_features/features/', 'annotation_path': 'data/datasets/vqa2/grid_features/annotations/', 'vocab_path': 'data/datasets/vqa2/defaults/extras/vocabs/', 'train_datasets': ['train'], 'test_datasets': ['oneval'], 'vqa_reader_train_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train']}, 'vqa_reader_test_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler_cfg': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'train_data': {'samples_per_gpu': 4, 'workers_per_gpu': 1, 'sampler_name': 'TrainingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}}, 'test_data': {'samples_per_gpu': 4, 'workers_per_gpu': 1, 'sampler_name': 'TestingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}, 'eval_period': 5000}, 'evaluator_type': 'VQA', 'optimizer': {'type': 'AdamW', 'lr': 5e-05, 'weight_decay': 0, 'eps': 1e-09, 'betas': [0.9, 0.98], 'training_encoder_lr_multiply': 1}, 'optimizer_config': {'grad_clip': None}, 'lr_config': {'use_warmup': True, 'lr_steps': [90000, 108000], 'lr_ratio': 0.2, 'warmup_factor': 0.25, 'warmup_iterations': 27000, 'policy': 'MultiStepScheduler'}, 'total_epochs': 13, 'checkpoint_config': {'period': 5000}, 'log_config': {'period': 50, 'hooks': [{'type': 'TextLoggerHook'}]}, 'dist_params': {'backend': 'nccl'}, 'log_level': 'INFO', 'work_dir': 'work_dirs/', 'load_from': None, 'resume_from': None, 'workflow': [('train', 1)], 'SEED': 39189013, 'CUDNN_BENCHMARK': False, 'model_device': 'cuda', 'find_unused_parameters': True, 'config_file': 'configs/mcan/mcan_vqa.py', 'resume': False, 'eval_only': False, 'num_gpus': 4, 'num_machines': 2, 'machine_rank': 1, 'dist_url': 'tcp://192.168.3.103:8686', 'opts': []}
[11/20 16:16:23] MIX INFO: Running with full config:
Config (path: configs/mcan/mcan_vqa.py): {'model': {'type': 'MCAN', 'embedding': [{'type': 'WordEmbedding', 'vocab_file': '/home/jinliang/.cache/torch/mmf/data/datasets/textvqa/defaults/extras/vocabs/vocabulary_100k.txt', 'embedding_dim': 300}, {'type': 'TextEmbedding', 'emb_type': 'mcan', 'hidden_dim': 1024, 'embedding_dim': 300, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'num_attn_pool': 1, 'num_feat': 2}], 'encoder': {'type': 'ImageFeatureEncoder', 'encoder_type': 'default'}, 'backbone': {'type': 'TwoBranchEmbedding', 'embedding_dim': 2048, 'hidden_dim': 1024, 'cond_dim': 1024, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'cbn_num_layers': 4}, 'combine_model': {'type': 'BranchCombineLayer', 'img_dim': 1024, 'ques_dim': 1024}, 'head': {'type': 'ClassifierLayer', 'classifier_type': 'triple_linear', 'in_dim': 2048, 'out_dim': 3129}}, 'dataset_type': 'VQADATASET', 'data_root': '/home/jinliang/.cache/torch/mmf/', 'feature_path': 'data/datasets/vqa2/grid_features/features/', 'annotation_path': 'data/datasets/vqa2/grid_features/annotations/', 'vocab_path': 'data/datasets/vqa2/defaults/extras/vocabs/', 'train_datasets': ['train'], 'test_datasets': ['oneval'], 'vqa_reader_train_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train']}, 'vqa_reader_test_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler_cfg': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'train_data': {'samples_per_gpu': 4, 'workers_per_gpu': 1, 'sampler_name': 'TrainingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}}, 'test_data': {'samples_per_gpu': 4, 'workers_per_gpu': 1, 'sampler_name': 'TestingSampler', 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}, 'eval_period': 5000}, 'evaluator_type': 'VQA', 'optimizer': {'type': 'AdamW', 'lr': 5e-05, 'weight_decay': 0, 'eps': 1e-09, 'betas': [0.9, 0.98], 'training_encoder_lr_multiply': 1}, 'optimizer_config': {'grad_clip': None}, 'lr_config': {'use_warmup': True, 'lr_steps': [90000, 108000], 'lr_ratio': 0.2, 'warmup_factor': 0.25, 'warmup_iterations': 27000, 'policy': 'MultiStepScheduler'}, 'total_epochs': 13, 'checkpoint_config': {'period': 5000}, 'log_config': {'period': 50, 'hooks': [{'type': 'TextLoggerHook'}]}, 'dist_params': {'backend': 'nccl'}, 'log_level': 'INFO', 'work_dir': 'work_dirs/', 'load_from': None, 'resume_from': None, 'workflow': [('train', 1)], 'SEED': 39189013, 'CUDNN_BENCHMARK': False, 'model_device': 'cuda', 'find_unused_parameters': True, 'config_file': 'configs/mcan/mcan_vqa.py', 'resume': False, 'eval_only': False, 'num_gpus': 4, 'num_machines': 2, 'machine_rank': 1, 'dist_url': 'tcp://192.168.3.103:8686', 'opts': []}
[11/20 16:16:32] MIX INFO: Organizer.init
[11/20 16:16:32] MIX INFO: Organizer.init
