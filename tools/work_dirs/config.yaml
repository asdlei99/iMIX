model = dict(
    type='MCAN',
    embedding=[
        dict(
            type='WordEmbedding',
            vocab_file=
            '/home/jinliang/.cache/torch/mmf/data/datasets/textvqa/defaults/extras/vocabs/vocabulary_100k.txt',
            embedding_dim=300),
        dict(
            type='TextEmbedding',
            emb_type='mcan',
            hidden_dim=1024,
            embedding_dim=300,
            num_attn=8,
            dropout=0.1,
            num_layers=6,
            num_attn_pool=1,
            num_feat=2)
    ],
    encoder=dict(type='ImageFeatureEncoder', encoder_type='default'),
    backbone=dict(
        type='TwoBranchEmbedding',
        embedding_dim=2048,
        hidden_dim=1024,
        cond_dim=1024,
        num_attn=8,
        dropout=0.1,
        num_layers=6,
        cbn_num_layers=4),
    combine_model=dict(type='BranchCombineLayer', img_dim=1024, ques_dim=1024),
    head=dict(
        type='ClassifierLayer',
        classifier_type='triple_linear',
        in_dim=2048,
        out_dim=3129))
dataset_type = 'VQADATASET'
data_root = '/home/jinliang/.cache/torch/mmf/'
feature_path = 'data/datasets/vqa2/grid_features/features/'
annotation_path = 'data/datasets/vqa2/grid_features/annotations/'
vocab_path = 'data/datasets/vqa2/defaults/extras/vocabs/'
train_datasets = ['train', 'val', 'visualgenome']
test_datasets = ['oneval']
vqa_reader_train_cfg = dict(
    type='VQAReader',
    mmf_features=dict(
        train=
        '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014',
        val=
        '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014',
        test=
        '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015',
        visualgenome=
        '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome',
        oneval=
        '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'
    ),
    mmf_annotations=dict(
        train=
        '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy',
        val=
        '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy',
        test=
        '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy',
        visualgenome=
        '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy',
        oneval=
        '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'
    ),
    datasets=['train', 'val', 'visualgenome'])
vqa_reader_test_cfg = dict(
    type='VQAReader',
    mmf_features=dict(
        train=
        '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014',
        val=
        '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014',
        test=
        '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015',
        visualgenome=
        '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome',
        oneval=
        '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'
    ),
    mmf_annotations=dict(
        train=
        '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy',
        val=
        '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy',
        test=
        '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy',
        visualgenome=
        '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy',
        oneval=
        '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'
    ),
    datasets=['oneval'])
vqa_info_cpler_cfg = dict(
    type='VQAInfoCpler',
    glove_weights='/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt',
    tokenizer='/home/datasets/VQA/bert/bert-base-uncased-vocab.txt',
    mmf_vocab=dict(
        answers_vqa=
        '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt',
        vocabulart_100k=
        '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt',
        vocabulary_vqa=
        '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'
    ))
train_data = dict(
    samples_per_gpu=2,
    workers_per_gpu=2,
    data=dict(
        type='VQADATASET',
        vqa_reader=dict(
            type='VQAReader',
            mmf_features=dict(
                train=
                '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014',
                val=
                '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014',
                test=
                '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015',
                visualgenome=
                '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome',
                oneval=
                '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'
            ),
            mmf_annotations=dict(
                train=
                '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy',
                val=
                '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy',
                test=
                '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy',
                visualgenome=
                '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy',
                oneval=
                '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'
            ),
            datasets=['train', 'val', 'visualgenome']),
        vqa_info_cpler=dict(
            type='VQAInfoCpler',
            glove_weights=
            '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt',
            tokenizer='/home/datasets/VQA/bert/bert-base-uncased-vocab.txt',
            mmf_vocab=dict(
                answers_vqa=
                '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt',
                vocabulart_100k=
                '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt',
                vocabulary_vqa=
                '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'
            ))))
test_data = dict(
    samples_per_gpu=2,
    workers_per_gpu=2,
    data=dict(
        type='VQADATASET',
        vqa_reader=dict(
            type='VQAReader',
            mmf_features=dict(
                train=
                '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014',
                val=
                '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014',
                test=
                '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015',
                visualgenome=
                '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome',
                oneval=
                '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'
            ),
            mmf_annotations=dict(
                train=
                '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy',
                val=
                '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy',
                test=
                '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy',
                visualgenome=
                '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy',
                oneval=
                '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'
            ),
            datasets=['oneval']),
        vqa_info_cpler=dict(
            type='VQAInfoCpler',
            glove_weights=
            '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt',
            tokenizer='/home/datasets/VQA/bert/bert-base-uncased-vocab.txt',
            mmf_vocab=dict(
                answers_vqa=
                '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt',
                vocabulart_100k=
                '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt',
                vocabulary_vqa=
                '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'
            ))),
    eval_period=1000)
evaluator_type = 'VQA'
optimizer = dict(type='AdamW', lr=0.0001, weight_decay=0, eps=1e-09)
optimizer_config = dict(grad_clip=None)
lr_config = dict(
    policy='step',
    warmup='linear',
    warmup_iters=27000,
    warmup_ratio=0.25,
    step=[90000, 108000])
max_iter = 118000
checkpoint_config = dict(period=100)
log_config = dict(period=2, hooks=[dict(type='TextLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
work_dir = './work_dirs'
load_from = None
resume_from = None
workflow = [('train', 1)]
SEED = 100
eval_only = False
gpu_ids = range(0, 1)
distributed = False
