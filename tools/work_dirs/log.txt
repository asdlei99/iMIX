[10/13 03:59:52] MIX INFO: Rank of current process: 0. World size: 1
[10/13 03:59:52] MIX INFO: Rank of current process: 0. World size: 1
[10/13 03:59:52] MIX INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.12 |Anaconda, Inc.| (default, Sep  8 2020, 23:10:56) [GCC 7.3.0]
numpy                   1.18.5
detectron2              failed to import
detectron2._C           failed to import
Compiler                c++ (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)
CUDA compiler           Cuda compilation tools, release 10.1, V10.1.243
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0+cu101 @/home/jinliang/miniconda3/envs/mmdet_jin/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   Tesla V100-SXM3-32GB
CUDA_HOME               /usr/local/cuda
Pillow                  6.2.2
torchvision             0.6.0+cu101 @/home/jinliang/miniconda3/envs/mmdet_jin/lib/python3.6/site-packages/torchvision
torchvision arch flags  sm_35, sm_50, sm_60, sm_70, sm_75
cv2                     4.4.0
----------------------  ---------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF,

[10/13 03:59:52] MIX INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.12 |Anaconda, Inc.| (default, Sep  8 2020, 23:10:56) [GCC 7.3.0]
numpy                   1.18.5
detectron2              failed to import
detectron2._C           failed to import
Compiler                c++ (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)
CUDA compiler           Cuda compilation tools, release 10.1, V10.1.243
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0+cu101 @/home/jinliang/miniconda3/envs/mmdet_jin/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   Tesla V100-SXM3-32GB
CUDA_HOME               /usr/local/cuda
Pillow                  6.2.2
torchvision             0.6.0+cu101 @/home/jinliang/miniconda3/envs/mmdet_jin/lib/python3.6/site-packages/torchvision
torchvision arch flags  sm_35, sm_50, sm_60, sm_70, sm_75
cv2                     4.4.0
----------------------  ---------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF,

[10/13 03:59:52] MIX INFO: Command line arguments: Namespace(config='/home/jinliang/code/mix/configs/mcan/mcan_vqa.py', eval_only=False, gpu_ids=None, gpus=None, launcher='none', local_rank=0, no_validate=False, resume_from=None, seed=None, work_dir=None)
[10/13 03:59:52] MIX INFO: Command line arguments: Namespace(config='/home/jinliang/code/mix/configs/mcan/mcan_vqa.py', eval_only=False, gpu_ids=None, gpus=None, launcher='none', local_rank=0, no_validate=False, resume_from=None, seed=None, work_dir=None)
[10/13 03:59:52] MIX INFO: Running with full config:
Config (path: /home/jinliang/code/mix/configs/mcan/mcan_vqa.py): {'model': {'type': 'MCAN', 'embedding': [{'type': 'WordEmbedding', 'vocab_file': '/home/jinliang/.cache/torch/mmf/data/datasets/textvqa/defaults/extras/vocabs/vocabulary_100k.txt', 'embedding_dim': 300}, {'type': 'TextEmbedding', 'emb_type': 'mcan', 'hidden_dim': 1024, 'embedding_dim': 300, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'num_attn_pool': 1, 'num_feat': 2}], 'encoder': {'type': 'ImageFeatureEncoder', 'encoder_type': 'default'}, 'backbone': {'type': 'TwoBranchEmbedding', 'embedding_dim': 2048, 'hidden_dim': 1024, 'cond_dim': 1024, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'cbn_num_layers': 4}, 'combine_model': {'type': 'BranchCombineLayer', 'img_dim': 1024, 'ques_dim': 1024}, 'head': {'type': 'ClassifierLayer', 'classifier_type': 'triple_linear', 'in_dim': 2048, 'out_dim': 3129}}, 'dataset_type': 'VQADATASET', 'data_root': '/home/jinliang/.cache/torch/mmf/', 'feature_path': 'data/datasets/vqa2/grid_features/features/', 'annotation_path': 'data/datasets/vqa2/grid_features/annotations/', 'vocab_path': 'data/datasets/vqa2/defaults/extras/vocabs/', 'train_datasets': ['train', 'val', 'visualgenome'], 'test_datasets': ['oneval'], 'vqa_reader_train_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val', 'visualgenome']}, 'vqa_reader_test_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler_cfg': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'train_data': {'samples_per_gpu': 2, 'workers_per_gpu': 2, 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val', 'visualgenome']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}}, 'test_data': {'samples_per_gpu': 2, 'workers_per_gpu': 2, 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}, 'eval_period': 1000}, 'evaluator_type': 'VQA', 'optimizer': {'type': 'AdamW', 'lr': 0.0001, 'weight_decay': 0, 'eps': 1e-09}, 'optimizer_config': {'grad_clip': None}, 'lr_config': {'policy': 'step', 'warmup': 'linear', 'warmup_iters': 27000, 'warmup_ratio': 0.25, 'step': [90000, 108000]}, 'max_iter': 118000, 'checkpoint_config': {'period': 100}, 'log_config': {'period': 2, 'hooks': [{'type': 'TextLoggerHook'}]}, 'dist_params': {'backend': 'nccl'}, 'log_level': 'INFO', 'work_dir': './work_dirs', 'load_from': None, 'resume_from': None, 'workflow': [('train', 1)], 'SEED': 100, 'eval_only': False, 'gpu_ids': range(0, 1), 'distributed': False}
[10/13 03:59:52] MIX INFO: Running with full config:
Config (path: /home/jinliang/code/mix/configs/mcan/mcan_vqa.py): {'model': {'type': 'MCAN', 'embedding': [{'type': 'WordEmbedding', 'vocab_file': '/home/jinliang/.cache/torch/mmf/data/datasets/textvqa/defaults/extras/vocabs/vocabulary_100k.txt', 'embedding_dim': 300}, {'type': 'TextEmbedding', 'emb_type': 'mcan', 'hidden_dim': 1024, 'embedding_dim': 300, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'num_attn_pool': 1, 'num_feat': 2}], 'encoder': {'type': 'ImageFeatureEncoder', 'encoder_type': 'default'}, 'backbone': {'type': 'TwoBranchEmbedding', 'embedding_dim': 2048, 'hidden_dim': 1024, 'cond_dim': 1024, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'cbn_num_layers': 4}, 'combine_model': {'type': 'BranchCombineLayer', 'img_dim': 1024, 'ques_dim': 1024}, 'head': {'type': 'ClassifierLayer', 'classifier_type': 'triple_linear', 'in_dim': 2048, 'out_dim': 3129}}, 'dataset_type': 'VQADATASET', 'data_root': '/home/jinliang/.cache/torch/mmf/', 'feature_path': 'data/datasets/vqa2/grid_features/features/', 'annotation_path': 'data/datasets/vqa2/grid_features/annotations/', 'vocab_path': 'data/datasets/vqa2/defaults/extras/vocabs/', 'train_datasets': ['train', 'val', 'visualgenome'], 'test_datasets': ['oneval'], 'vqa_reader_train_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val', 'visualgenome']}, 'vqa_reader_test_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler_cfg': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'train_data': {'samples_per_gpu': 2, 'workers_per_gpu': 2, 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val', 'visualgenome']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}}, 'test_data': {'samples_per_gpu': 2, 'workers_per_gpu': 2, 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}, 'eval_period': 1000}, 'evaluator_type': 'VQA', 'optimizer': {'type': 'AdamW', 'lr': 0.0001, 'weight_decay': 0, 'eps': 1e-09}, 'optimizer_config': {'grad_clip': None}, 'lr_config': {'policy': 'step', 'warmup': 'linear', 'warmup_iters': 27000, 'warmup_ratio': 0.25, 'step': [90000, 108000]}, 'max_iter': 118000, 'checkpoint_config': {'period': 100}, 'log_config': {'period': 2, 'hooks': [{'type': 'TextLoggerHook'}]}, 'dist_params': {'backend': 'nccl'}, 'log_level': 'INFO', 'work_dir': './work_dirs', 'load_from': None, 'resume_from': None, 'workflow': [('train', 1)], 'SEED': 100, 'eval_only': False, 'gpu_ids': range(0, 1), 'distributed': False}
[10/13 04:00:10] MIX INFO: Full config saved to ./work_dirs/config.yaml
[10/13 04:00:10] MIX INFO: Full config saved to ./work_dirs/config.yaml
[10/13 04:08:56] MIX INFO: Rank of current process: 0. World size: 1
[10/13 04:08:56] MIX INFO: Rank of current process: 0. World size: 1
[10/13 04:08:56] MIX INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.12 |Anaconda, Inc.| (default, Sep  8 2020, 23:10:56) [GCC 7.3.0]
numpy                   1.18.5
detectron2              failed to import
detectron2._C           failed to import
Compiler                c++ (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)
CUDA compiler           Cuda compilation tools, release 10.1, V10.1.243
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0+cu101 @/home/jinliang/miniconda3/envs/mmdet_jin/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   Tesla V100-SXM3-32GB
CUDA_HOME               /usr/local/cuda
Pillow                  6.2.2
torchvision             0.6.0+cu101 @/home/jinliang/miniconda3/envs/mmdet_jin/lib/python3.6/site-packages/torchvision
torchvision arch flags  sm_35, sm_50, sm_60, sm_70, sm_75
cv2                     4.4.0
----------------------  ---------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF,

[10/13 04:08:56] MIX INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.12 |Anaconda, Inc.| (default, Sep  8 2020, 23:10:56) [GCC 7.3.0]
numpy                   1.18.5
detectron2              failed to import
detectron2._C           failed to import
Compiler                c++ (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)
CUDA compiler           Cuda compilation tools, release 10.1, V10.1.243
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0+cu101 @/home/jinliang/miniconda3/envs/mmdet_jin/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   Tesla V100-SXM3-32GB
CUDA_HOME               /usr/local/cuda
Pillow                  6.2.2
torchvision             0.6.0+cu101 @/home/jinliang/miniconda3/envs/mmdet_jin/lib/python3.6/site-packages/torchvision
torchvision arch flags  sm_35, sm_50, sm_60, sm_70, sm_75
cv2                     4.4.0
----------------------  ---------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF,

[10/13 04:08:56] MIX INFO: Command line arguments: Namespace(config='/home/jinliang/code/mix/configs/mcan/mcan_vqa.py', eval_only=False, gpu_ids=None, gpus=None, launcher='none', local_rank=0, no_validate=False, resume_from=None, seed=None, work_dir=None)
[10/13 04:08:56] MIX INFO: Command line arguments: Namespace(config='/home/jinliang/code/mix/configs/mcan/mcan_vqa.py', eval_only=False, gpu_ids=None, gpus=None, launcher='none', local_rank=0, no_validate=False, resume_from=None, seed=None, work_dir=None)
[10/13 04:08:56] MIX INFO: Running with full config:
Config (path: /home/jinliang/code/mix/configs/mcan/mcan_vqa.py): {'model': {'type': 'MCAN', 'embedding': [{'type': 'WordEmbedding', 'vocab_file': '/home/jinliang/.cache/torch/mmf/data/datasets/textvqa/defaults/extras/vocabs/vocabulary_100k.txt', 'embedding_dim': 300}, {'type': 'TextEmbedding', 'emb_type': 'mcan', 'hidden_dim': 1024, 'embedding_dim': 300, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'num_attn_pool': 1, 'num_feat': 2}], 'encoder': {'type': 'ImageFeatureEncoder', 'encoder_type': 'default'}, 'backbone': {'type': 'TwoBranchEmbedding', 'embedding_dim': 2048, 'hidden_dim': 1024, 'cond_dim': 1024, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'cbn_num_layers': 4}, 'combine_model': {'type': 'BranchCombineLayer', 'img_dim': 1024, 'ques_dim': 1024}, 'head': {'type': 'ClassifierLayer', 'classifier_type': 'triple_linear', 'in_dim': 2048, 'out_dim': 3129}}, 'dataset_type': 'VQADATASET', 'data_root': '/home/jinliang/.cache/torch/mmf/', 'feature_path': 'data/datasets/vqa2/grid_features/features/', 'annotation_path': 'data/datasets/vqa2/grid_features/annotations/', 'vocab_path': 'data/datasets/vqa2/defaults/extras/vocabs/', 'train_datasets': ['train', 'val', 'visualgenome'], 'test_datasets': ['oneval'], 'vqa_reader_train_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val', 'visualgenome']}, 'vqa_reader_test_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler_cfg': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'train_data': {'samples_per_gpu': 2, 'workers_per_gpu': 2, 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val', 'visualgenome']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}}, 'test_data': {'samples_per_gpu': 2, 'workers_per_gpu': 2, 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}, 'eval_period': 1000}, 'evaluator_type': 'VQA', 'optimizer': {'type': 'AdamW', 'lr': 0.0001, 'weight_decay': 0, 'eps': 1e-09}, 'optimizer_config': {'grad_clip': None}, 'lr_config': {'policy': 'step', 'warmup': 'linear', 'warmup_iters': 27000, 'warmup_ratio': 0.25, 'step': [90000, 108000]}, 'max_iter': 118000, 'checkpoint_config': {'period': 100}, 'log_config': {'period': 2, 'hooks': [{'type': 'TextLoggerHook'}]}, 'dist_params': {'backend': 'nccl'}, 'log_level': 'INFO', 'work_dir': './work_dirs', 'load_from': None, 'resume_from': None, 'workflow': [('train', 1)], 'SEED': 100, 'eval_only': False, 'gpu_ids': range(0, 1), 'distributed': False}
[10/13 04:08:56] MIX INFO: Running with full config:
Config (path: /home/jinliang/code/mix/configs/mcan/mcan_vqa.py): {'model': {'type': 'MCAN', 'embedding': [{'type': 'WordEmbedding', 'vocab_file': '/home/jinliang/.cache/torch/mmf/data/datasets/textvqa/defaults/extras/vocabs/vocabulary_100k.txt', 'embedding_dim': 300}, {'type': 'TextEmbedding', 'emb_type': 'mcan', 'hidden_dim': 1024, 'embedding_dim': 300, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'num_attn_pool': 1, 'num_feat': 2}], 'encoder': {'type': 'ImageFeatureEncoder', 'encoder_type': 'default'}, 'backbone': {'type': 'TwoBranchEmbedding', 'embedding_dim': 2048, 'hidden_dim': 1024, 'cond_dim': 1024, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'cbn_num_layers': 4}, 'combine_model': {'type': 'BranchCombineLayer', 'img_dim': 1024, 'ques_dim': 1024}, 'head': {'type': 'ClassifierLayer', 'classifier_type': 'triple_linear', 'in_dim': 2048, 'out_dim': 3129}}, 'dataset_type': 'VQADATASET', 'data_root': '/home/jinliang/.cache/torch/mmf/', 'feature_path': 'data/datasets/vqa2/grid_features/features/', 'annotation_path': 'data/datasets/vqa2/grid_features/annotations/', 'vocab_path': 'data/datasets/vqa2/defaults/extras/vocabs/', 'train_datasets': ['train', 'val', 'visualgenome'], 'test_datasets': ['oneval'], 'vqa_reader_train_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val', 'visualgenome']}, 'vqa_reader_test_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler_cfg': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'train_data': {'samples_per_gpu': 2, 'workers_per_gpu': 2, 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val', 'visualgenome']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}}, 'test_data': {'samples_per_gpu': 2, 'workers_per_gpu': 2, 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}, 'eval_period': 1000}, 'evaluator_type': 'VQA', 'optimizer': {'type': 'AdamW', 'lr': 0.0001, 'weight_decay': 0, 'eps': 1e-09}, 'optimizer_config': {'grad_clip': None}, 'lr_config': {'policy': 'step', 'warmup': 'linear', 'warmup_iters': 27000, 'warmup_ratio': 0.25, 'step': [90000, 108000]}, 'max_iter': 118000, 'checkpoint_config': {'period': 100}, 'log_config': {'period': 2, 'hooks': [{'type': 'TextLoggerHook'}]}, 'dist_params': {'backend': 'nccl'}, 'log_level': 'INFO', 'work_dir': './work_dirs', 'load_from': None, 'resume_from': None, 'workflow': [('train', 1)], 'SEED': 100, 'eval_only': False, 'gpu_ids': range(0, 1), 'distributed': False}
[10/13 04:09:12] MIX INFO: Full config saved to ./work_dirs/config.yaml
[10/13 04:09:12] MIX INFO: Full config saved to ./work_dirs/config.yaml
[10/13 04:10:11] MIX INFO: Rank of current process: 0. World size: 1
[10/13 04:10:11] MIX INFO: Rank of current process: 0. World size: 1
[10/13 04:10:11] MIX INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.12 |Anaconda, Inc.| (default, Sep  8 2020, 23:10:56) [GCC 7.3.0]
numpy                   1.18.5
detectron2              failed to import
detectron2._C           failed to import
Compiler                c++ (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)
CUDA compiler           Cuda compilation tools, release 10.1, V10.1.243
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0+cu101 @/home/jinliang/miniconda3/envs/mmdet_jin/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   Tesla V100-SXM3-32GB
CUDA_HOME               /usr/local/cuda
Pillow                  6.2.2
torchvision             0.6.0+cu101 @/home/jinliang/miniconda3/envs/mmdet_jin/lib/python3.6/site-packages/torchvision
torchvision arch flags  sm_35, sm_50, sm_60, sm_70, sm_75
cv2                     4.4.0
----------------------  ---------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF,

[10/13 04:10:11] MIX INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.12 |Anaconda, Inc.| (default, Sep  8 2020, 23:10:56) [GCC 7.3.0]
numpy                   1.18.5
detectron2              failed to import
detectron2._C           failed to import
Compiler                c++ (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)
CUDA compiler           Cuda compilation tools, release 10.1, V10.1.243
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0+cu101 @/home/jinliang/miniconda3/envs/mmdet_jin/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   Tesla V100-SXM3-32GB
CUDA_HOME               /usr/local/cuda
Pillow                  6.2.2
torchvision             0.6.0+cu101 @/home/jinliang/miniconda3/envs/mmdet_jin/lib/python3.6/site-packages/torchvision
torchvision arch flags  sm_35, sm_50, sm_60, sm_70, sm_75
cv2                     4.4.0
----------------------  ---------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF,

[10/13 04:10:11] MIX INFO: Command line arguments: Namespace(config='/home/jinliang/code/mix/configs/mcan/mcan_vqa.py', eval_only=False, gpu_ids=None, gpus=None, launcher='none', local_rank=0, no_validate=False, resume_from=None, seed=None, work_dir=None)
[10/13 04:10:11] MIX INFO: Command line arguments: Namespace(config='/home/jinliang/code/mix/configs/mcan/mcan_vqa.py', eval_only=False, gpu_ids=None, gpus=None, launcher='none', local_rank=0, no_validate=False, resume_from=None, seed=None, work_dir=None)
[10/13 04:10:11] MIX INFO: Running with full config:
Config (path: /home/jinliang/code/mix/configs/mcan/mcan_vqa.py): {'model': {'type': 'MCAN', 'embedding': [{'type': 'WordEmbedding', 'vocab_file': '/home/jinliang/.cache/torch/mmf/data/datasets/textvqa/defaults/extras/vocabs/vocabulary_100k.txt', 'embedding_dim': 300}, {'type': 'TextEmbedding', 'emb_type': 'mcan', 'hidden_dim': 1024, 'embedding_dim': 300, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'num_attn_pool': 1, 'num_feat': 2}], 'encoder': {'type': 'ImageFeatureEncoder', 'encoder_type': 'default'}, 'backbone': {'type': 'TwoBranchEmbedding', 'embedding_dim': 2048, 'hidden_dim': 1024, 'cond_dim': 1024, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'cbn_num_layers': 4}, 'combine_model': {'type': 'BranchCombineLayer', 'img_dim': 1024, 'ques_dim': 1024}, 'head': {'type': 'ClassifierLayer', 'classifier_type': 'triple_linear', 'in_dim': 2048, 'out_dim': 3129}}, 'dataset_type': 'VQADATASET', 'data_root': '/home/jinliang/.cache/torch/mmf/', 'feature_path': 'data/datasets/vqa2/grid_features/features/', 'annotation_path': 'data/datasets/vqa2/grid_features/annotations/', 'vocab_path': 'data/datasets/vqa2/defaults/extras/vocabs/', 'train_datasets': ['train', 'val', 'visualgenome'], 'test_datasets': ['oneval'], 'vqa_reader_train_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val', 'visualgenome']}, 'vqa_reader_test_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler_cfg': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'train_data': {'samples_per_gpu': 2, 'workers_per_gpu': 2, 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val', 'visualgenome']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}}, 'test_data': {'samples_per_gpu': 2, 'workers_per_gpu': 2, 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}, 'eval_period': 1000}, 'evaluator_type': 'VQA', 'optimizer': {'type': 'AdamW', 'lr': 0.0001, 'weight_decay': 0, 'eps': 1e-09}, 'optimizer_config': {'grad_clip': None}, 'lr_config': {'policy': 'step', 'warmup': 'linear', 'warmup_iters': 27000, 'warmup_ratio': 0.25, 'step': [90000, 108000]}, 'max_iter': 118000, 'checkpoint_config': {'period': 100}, 'log_config': {'period': 2, 'hooks': [{'type': 'TextLoggerHook'}]}, 'dist_params': {'backend': 'nccl'}, 'log_level': 'INFO', 'work_dir': './work_dirs', 'load_from': None, 'resume_from': None, 'workflow': [('train', 1)], 'SEED': 100, 'eval_only': False, 'gpu_ids': range(0, 1), 'distributed': False}
[10/13 04:10:11] MIX INFO: Running with full config:
Config (path: /home/jinliang/code/mix/configs/mcan/mcan_vqa.py): {'model': {'type': 'MCAN', 'embedding': [{'type': 'WordEmbedding', 'vocab_file': '/home/jinliang/.cache/torch/mmf/data/datasets/textvqa/defaults/extras/vocabs/vocabulary_100k.txt', 'embedding_dim': 300}, {'type': 'TextEmbedding', 'emb_type': 'mcan', 'hidden_dim': 1024, 'embedding_dim': 300, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'num_attn_pool': 1, 'num_feat': 2}], 'encoder': {'type': 'ImageFeatureEncoder', 'encoder_type': 'default'}, 'backbone': {'type': 'TwoBranchEmbedding', 'embedding_dim': 2048, 'hidden_dim': 1024, 'cond_dim': 1024, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'cbn_num_layers': 4}, 'combine_model': {'type': 'BranchCombineLayer', 'img_dim': 1024, 'ques_dim': 1024}, 'head': {'type': 'ClassifierLayer', 'classifier_type': 'triple_linear', 'in_dim': 2048, 'out_dim': 3129}}, 'dataset_type': 'VQADATASET', 'data_root': '/home/jinliang/.cache/torch/mmf/', 'feature_path': 'data/datasets/vqa2/grid_features/features/', 'annotation_path': 'data/datasets/vqa2/grid_features/annotations/', 'vocab_path': 'data/datasets/vqa2/defaults/extras/vocabs/', 'train_datasets': ['train', 'val', 'visualgenome'], 'test_datasets': ['oneval'], 'vqa_reader_train_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val', 'visualgenome']}, 'vqa_reader_test_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler_cfg': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'train_data': {'samples_per_gpu': 2, 'workers_per_gpu': 2, 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val', 'visualgenome']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}}, 'test_data': {'samples_per_gpu': 2, 'workers_per_gpu': 2, 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}, 'eval_period': 1000}, 'evaluator_type': 'VQA', 'optimizer': {'type': 'AdamW', 'lr': 0.0001, 'weight_decay': 0, 'eps': 1e-09}, 'optimizer_config': {'grad_clip': None}, 'lr_config': {'policy': 'step', 'warmup': 'linear', 'warmup_iters': 27000, 'warmup_ratio': 0.25, 'step': [90000, 108000]}, 'max_iter': 118000, 'checkpoint_config': {'period': 100}, 'log_config': {'period': 2, 'hooks': [{'type': 'TextLoggerHook'}]}, 'dist_params': {'backend': 'nccl'}, 'log_level': 'INFO', 'work_dir': './work_dirs', 'load_from': None, 'resume_from': None, 'workflow': [('train', 1)], 'SEED': 100, 'eval_only': False, 'gpu_ids': range(0, 1), 'distributed': False}
[10/13 04:11:02] MIX INFO: Rank of current process: 0. World size: 1
[10/13 04:11:02] MIX INFO: Rank of current process: 0. World size: 1
[10/13 04:11:02] MIX INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.12 |Anaconda, Inc.| (default, Sep  8 2020, 23:10:56) [GCC 7.3.0]
numpy                   1.18.5
detectron2              failed to import
detectron2._C           failed to import
Compiler                c++ (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)
CUDA compiler           Cuda compilation tools, release 10.1, V10.1.243
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0+cu101 @/home/jinliang/miniconda3/envs/mmdet_jin/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   Tesla V100-SXM3-32GB
CUDA_HOME               /usr/local/cuda
Pillow                  6.2.2
torchvision             0.6.0+cu101 @/home/jinliang/miniconda3/envs/mmdet_jin/lib/python3.6/site-packages/torchvision
torchvision arch flags  sm_35, sm_50, sm_60, sm_70, sm_75
cv2                     4.4.0
----------------------  ---------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF,

[10/13 04:11:02] MIX INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.12 |Anaconda, Inc.| (default, Sep  8 2020, 23:10:56) [GCC 7.3.0]
numpy                   1.18.5
detectron2              failed to import
detectron2._C           failed to import
Compiler                c++ (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)
CUDA compiler           Cuda compilation tools, release 10.1, V10.1.243
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0+cu101 @/home/jinliang/miniconda3/envs/mmdet_jin/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   Tesla V100-SXM3-32GB
CUDA_HOME               /usr/local/cuda
Pillow                  6.2.2
torchvision             0.6.0+cu101 @/home/jinliang/miniconda3/envs/mmdet_jin/lib/python3.6/site-packages/torchvision
torchvision arch flags  sm_35, sm_50, sm_60, sm_70, sm_75
cv2                     4.4.0
----------------------  ---------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF,

[10/13 04:11:02] MIX INFO: Command line arguments: Namespace(config='/home/jinliang/code/mix/configs/mcan/mcan_vqa.py', eval_only=False, gpu_ids=None, gpus=None, launcher='none', local_rank=0, no_validate=False, resume_from=None, seed=None, work_dir=None)
[10/13 04:11:02] MIX INFO: Command line arguments: Namespace(config='/home/jinliang/code/mix/configs/mcan/mcan_vqa.py', eval_only=False, gpu_ids=None, gpus=None, launcher='none', local_rank=0, no_validate=False, resume_from=None, seed=None, work_dir=None)
[10/13 04:11:02] MIX INFO: Running with full config:
Config (path: /home/jinliang/code/mix/configs/mcan/mcan_vqa.py): {'model': {'type': 'MCAN', 'embedding': [{'type': 'WordEmbedding', 'vocab_file': '/home/jinliang/.cache/torch/mmf/data/datasets/textvqa/defaults/extras/vocabs/vocabulary_100k.txt', 'embedding_dim': 300}, {'type': 'TextEmbedding', 'emb_type': 'mcan', 'hidden_dim': 1024, 'embedding_dim': 300, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'num_attn_pool': 1, 'num_feat': 2}], 'encoder': {'type': 'ImageFeatureEncoder', 'encoder_type': 'default'}, 'backbone': {'type': 'TwoBranchEmbedding', 'embedding_dim': 2048, 'hidden_dim': 1024, 'cond_dim': 1024, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'cbn_num_layers': 4}, 'combine_model': {'type': 'BranchCombineLayer', 'img_dim': 1024, 'ques_dim': 1024}, 'head': {'type': 'ClassifierLayer', 'classifier_type': 'triple_linear', 'in_dim': 2048, 'out_dim': 3129}}, 'dataset_type': 'VQADATASET', 'data_root': '/home/jinliang/.cache/torch/mmf/', 'feature_path': 'data/datasets/vqa2/grid_features/features/', 'annotation_path': 'data/datasets/vqa2/grid_features/annotations/', 'vocab_path': 'data/datasets/vqa2/defaults/extras/vocabs/', 'train_datasets': ['train', 'val', 'visualgenome'], 'test_datasets': ['oneval'], 'vqa_reader_train_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val', 'visualgenome']}, 'vqa_reader_test_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler_cfg': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'train_data': {'samples_per_gpu': 2, 'workers_per_gpu': 2, 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val', 'visualgenome']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}}, 'test_data': {'samples_per_gpu': 2, 'workers_per_gpu': 2, 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}, 'eval_period': 1000}, 'evaluator_type': 'VQA', 'optimizer': {'type': 'AdamW', 'lr': 0.0001, 'weight_decay': 0, 'eps': 1e-09}, 'optimizer_config': {'grad_clip': None}, 'lr_config': {'policy': 'step', 'warmup': 'linear', 'warmup_iters': 27000, 'warmup_ratio': 0.25, 'step': [90000, 108000]}, 'max_iter': 118000, 'checkpoint_config': {'period': 100}, 'log_config': {'period': 2, 'hooks': [{'type': 'TextLoggerHook'}]}, 'dist_params': {'backend': 'nccl'}, 'log_level': 'INFO', 'work_dir': './work_dirs', 'load_from': None, 'resume_from': None, 'workflow': [('train', 1)], 'SEED': 100, 'eval_only': False, 'gpu_ids': range(0, 1), 'distributed': False}
[10/13 04:11:02] MIX INFO: Running with full config:
Config (path: /home/jinliang/code/mix/configs/mcan/mcan_vqa.py): {'model': {'type': 'MCAN', 'embedding': [{'type': 'WordEmbedding', 'vocab_file': '/home/jinliang/.cache/torch/mmf/data/datasets/textvqa/defaults/extras/vocabs/vocabulary_100k.txt', 'embedding_dim': 300}, {'type': 'TextEmbedding', 'emb_type': 'mcan', 'hidden_dim': 1024, 'embedding_dim': 300, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'num_attn_pool': 1, 'num_feat': 2}], 'encoder': {'type': 'ImageFeatureEncoder', 'encoder_type': 'default'}, 'backbone': {'type': 'TwoBranchEmbedding', 'embedding_dim': 2048, 'hidden_dim': 1024, 'cond_dim': 1024, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'cbn_num_layers': 4}, 'combine_model': {'type': 'BranchCombineLayer', 'img_dim': 1024, 'ques_dim': 1024}, 'head': {'type': 'ClassifierLayer', 'classifier_type': 'triple_linear', 'in_dim': 2048, 'out_dim': 3129}}, 'dataset_type': 'VQADATASET', 'data_root': '/home/jinliang/.cache/torch/mmf/', 'feature_path': 'data/datasets/vqa2/grid_features/features/', 'annotation_path': 'data/datasets/vqa2/grid_features/annotations/', 'vocab_path': 'data/datasets/vqa2/defaults/extras/vocabs/', 'train_datasets': ['train', 'val', 'visualgenome'], 'test_datasets': ['oneval'], 'vqa_reader_train_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val', 'visualgenome']}, 'vqa_reader_test_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler_cfg': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'train_data': {'samples_per_gpu': 2, 'workers_per_gpu': 2, 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val', 'visualgenome']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}}, 'test_data': {'samples_per_gpu': 2, 'workers_per_gpu': 2, 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}, 'eval_period': 1000}, 'evaluator_type': 'VQA', 'optimizer': {'type': 'AdamW', 'lr': 0.0001, 'weight_decay': 0, 'eps': 1e-09}, 'optimizer_config': {'grad_clip': None}, 'lr_config': {'policy': 'step', 'warmup': 'linear', 'warmup_iters': 27000, 'warmup_ratio': 0.25, 'step': [90000, 108000]}, 'max_iter': 118000, 'checkpoint_config': {'period': 100}, 'log_config': {'period': 2, 'hooks': [{'type': 'TextLoggerHook'}]}, 'dist_params': {'backend': 'nccl'}, 'log_level': 'INFO', 'work_dir': './work_dirs', 'load_from': None, 'resume_from': None, 'workflow': [('train', 1)], 'SEED': 100, 'eval_only': False, 'gpu_ids': range(0, 1), 'distributed': False}
[10/13 04:11:18] MIX INFO: Full config saved to ./work_dirs/config.yaml
[10/13 04:11:18] MIX INFO: Full config saved to ./work_dirs/config.yaml
[10/13 04:54:32] MIX INFO: Rank of current process: 0. World size: 1
[10/13 04:54:32] MIX INFO: Rank of current process: 0. World size: 1
[10/13 04:54:32] MIX INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.12 |Anaconda, Inc.| (default, Sep  8 2020, 23:10:56) [GCC 7.3.0]
numpy                   1.18.5
detectron2              failed to import
detectron2._C           failed to import
Compiler                c++ (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)
CUDA compiler           Cuda compilation tools, release 10.1, V10.1.243
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0+cu101 @/home/jinliang/miniconda3/envs/mmdet_jin/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   Tesla V100-SXM3-32GB
CUDA_HOME               /usr/local/cuda
Pillow                  6.2.2
torchvision             0.6.0+cu101 @/home/jinliang/miniconda3/envs/mmdet_jin/lib/python3.6/site-packages/torchvision
torchvision arch flags  sm_35, sm_50, sm_60, sm_70, sm_75
cv2                     4.4.0
----------------------  ---------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF,

[10/13 04:54:32] MIX INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.12 |Anaconda, Inc.| (default, Sep  8 2020, 23:10:56) [GCC 7.3.0]
numpy                   1.18.5
detectron2              failed to import
detectron2._C           failed to import
Compiler                c++ (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)
CUDA compiler           Cuda compilation tools, release 10.1, V10.1.243
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0+cu101 @/home/jinliang/miniconda3/envs/mmdet_jin/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   Tesla V100-SXM3-32GB
CUDA_HOME               /usr/local/cuda
Pillow                  6.2.2
torchvision             0.6.0+cu101 @/home/jinliang/miniconda3/envs/mmdet_jin/lib/python3.6/site-packages/torchvision
torchvision arch flags  sm_35, sm_50, sm_60, sm_70, sm_75
cv2                     4.4.0
----------------------  ---------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF,

[10/13 04:54:32] MIX INFO: Command line arguments: Namespace(config='/home/jinliang/code/mix/configs/mcan/mcan_vqa.py', eval_only=False, gpu_ids=None, gpus=None, launcher='none', local_rank=0, no_validate=False, resume_from=None, seed=None, work_dir=None)
[10/13 04:54:32] MIX INFO: Command line arguments: Namespace(config='/home/jinliang/code/mix/configs/mcan/mcan_vqa.py', eval_only=False, gpu_ids=None, gpus=None, launcher='none', local_rank=0, no_validate=False, resume_from=None, seed=None, work_dir=None)
[10/13 04:54:32] MIX INFO: Running with full config:
Config (path: /home/jinliang/code/mix/configs/mcan/mcan_vqa.py): {'model': {'type': 'MCAN', 'embedding': [{'type': 'WordEmbedding', 'vocab_file': '/home/jinliang/.cache/torch/mmf/data/datasets/textvqa/defaults/extras/vocabs/vocabulary_100k.txt', 'embedding_dim': 300}, {'type': 'TextEmbedding', 'emb_type': 'mcan', 'hidden_dim': 1024, 'embedding_dim': 300, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'num_attn_pool': 1, 'num_feat': 2}], 'encoder': {'type': 'ImageFeatureEncoder', 'encoder_type': 'default'}, 'backbone': {'type': 'TwoBranchEmbedding', 'embedding_dim': 2048, 'hidden_dim': 1024, 'cond_dim': 1024, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'cbn_num_layers': 4}, 'combine_model': {'type': 'BranchCombineLayer', 'img_dim': 1024, 'ques_dim': 1024}, 'head': {'type': 'ClassifierLayer', 'classifier_type': 'triple_linear', 'in_dim': 2048, 'out_dim': 3129}}, 'dataset_type': 'VQADATASET', 'data_root': '/home/jinliang/.cache/torch/mmf/', 'feature_path': 'data/datasets/vqa2/grid_features/features/', 'annotation_path': 'data/datasets/vqa2/grid_features/annotations/', 'vocab_path': 'data/datasets/vqa2/defaults/extras/vocabs/', 'train_datasets': ['train', 'val', 'visualgenome'], 'test_datasets': ['oneval'], 'vqa_reader_train_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val', 'visualgenome']}, 'vqa_reader_test_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler_cfg': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'train_data': {'samples_per_gpu': 2, 'workers_per_gpu': 2, 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val', 'visualgenome']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}}, 'test_data': {'samples_per_gpu': 2, 'workers_per_gpu': 2, 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}, 'eval_period': 1000}, 'evaluator_type': 'VQA', 'optimizer': {'type': 'AdamW', 'lr': 0.0001, 'weight_decay': 0, 'eps': 1e-09}, 'optimizer_config': {'grad_clip': None}, 'lr_config': {'policy': 'step', 'warmup': 'linear', 'warmup_iters': 27000, 'warmup_ratio': 0.25, 'step': [90000, 108000]}, 'max_iter': 118000, 'checkpoint_config': {'period': 100}, 'log_config': {'period': 2, 'hooks': [{'type': 'TextLoggerHook'}]}, 'dist_params': {'backend': 'nccl'}, 'log_level': 'INFO', 'work_dir': './work_dirs', 'load_from': None, 'resume_from': None, 'workflow': [('train', 1)], 'SEED': 100, 'eval_only': False, 'gpu_ids': range(0, 1), 'distributed': False}
[10/13 04:54:32] MIX INFO: Running with full config:
Config (path: /home/jinliang/code/mix/configs/mcan/mcan_vqa.py): {'model': {'type': 'MCAN', 'embedding': [{'type': 'WordEmbedding', 'vocab_file': '/home/jinliang/.cache/torch/mmf/data/datasets/textvqa/defaults/extras/vocabs/vocabulary_100k.txt', 'embedding_dim': 300}, {'type': 'TextEmbedding', 'emb_type': 'mcan', 'hidden_dim': 1024, 'embedding_dim': 300, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'num_attn_pool': 1, 'num_feat': 2}], 'encoder': {'type': 'ImageFeatureEncoder', 'encoder_type': 'default'}, 'backbone': {'type': 'TwoBranchEmbedding', 'embedding_dim': 2048, 'hidden_dim': 1024, 'cond_dim': 1024, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'cbn_num_layers': 4}, 'combine_model': {'type': 'BranchCombineLayer', 'img_dim': 1024, 'ques_dim': 1024}, 'head': {'type': 'ClassifierLayer', 'classifier_type': 'triple_linear', 'in_dim': 2048, 'out_dim': 3129}}, 'dataset_type': 'VQADATASET', 'data_root': '/home/jinliang/.cache/torch/mmf/', 'feature_path': 'data/datasets/vqa2/grid_features/features/', 'annotation_path': 'data/datasets/vqa2/grid_features/annotations/', 'vocab_path': 'data/datasets/vqa2/defaults/extras/vocabs/', 'train_datasets': ['train', 'val', 'visualgenome'], 'test_datasets': ['oneval'], 'vqa_reader_train_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val', 'visualgenome']}, 'vqa_reader_test_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler_cfg': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'train_data': {'samples_per_gpu': 2, 'workers_per_gpu': 2, 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val', 'visualgenome']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}}, 'test_data': {'samples_per_gpu': 2, 'workers_per_gpu': 2, 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}, 'eval_period': 1000}, 'evaluator_type': 'VQA', 'optimizer': {'type': 'AdamW', 'lr': 0.0001, 'weight_decay': 0, 'eps': 1e-09}, 'optimizer_config': {'grad_clip': None}, 'lr_config': {'policy': 'step', 'warmup': 'linear', 'warmup_iters': 27000, 'warmup_ratio': 0.25, 'step': [90000, 108000]}, 'max_iter': 118000, 'checkpoint_config': {'period': 100}, 'log_config': {'period': 2, 'hooks': [{'type': 'TextLoggerHook'}]}, 'dist_params': {'backend': 'nccl'}, 'log_level': 'INFO', 'work_dir': './work_dirs', 'load_from': None, 'resume_from': None, 'workflow': [('train', 1)], 'SEED': 100, 'eval_only': False, 'gpu_ids': range(0, 1), 'distributed': False}
[10/13 04:54:48] MIX INFO: Full config saved to ./work_dirs/config.yaml
[10/13 04:54:48] MIX INFO: Full config saved to ./work_dirs/config.yaml
[10/13 04:57:56] MIX INFO: Rank of current process: 0. World size: 1
[10/13 04:57:56] MIX INFO: Rank of current process: 0. World size: 1
[10/13 04:57:56] MIX INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.12 |Anaconda, Inc.| (default, Sep  8 2020, 23:10:56) [GCC 7.3.0]
numpy                   1.18.5
detectron2              failed to import
detectron2._C           failed to import
Compiler                c++ (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)
CUDA compiler           Cuda compilation tools, release 10.1, V10.1.243
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0+cu101 @/home/jinliang/miniconda3/envs/mmdet_jin/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   Tesla V100-SXM3-32GB
CUDA_HOME               /usr/local/cuda
Pillow                  6.2.2
torchvision             0.6.0+cu101 @/home/jinliang/miniconda3/envs/mmdet_jin/lib/python3.6/site-packages/torchvision
torchvision arch flags  sm_35, sm_50, sm_60, sm_70, sm_75
cv2                     4.4.0
----------------------  ---------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF,

[10/13 04:57:56] MIX INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.12 |Anaconda, Inc.| (default, Sep  8 2020, 23:10:56) [GCC 7.3.0]
numpy                   1.18.5
detectron2              failed to import
detectron2._C           failed to import
Compiler                c++ (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)
CUDA compiler           Cuda compilation tools, release 10.1, V10.1.243
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0+cu101 @/home/jinliang/miniconda3/envs/mmdet_jin/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   Tesla V100-SXM3-32GB
CUDA_HOME               /usr/local/cuda
Pillow                  6.2.2
torchvision             0.6.0+cu101 @/home/jinliang/miniconda3/envs/mmdet_jin/lib/python3.6/site-packages/torchvision
torchvision arch flags  sm_35, sm_50, sm_60, sm_70, sm_75
cv2                     4.4.0
----------------------  ---------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF,

[10/13 04:57:56] MIX INFO: Command line arguments: Namespace(config='/home/jinliang/code/mix/configs/mcan/mcan_vqa.py', eval_only=False, gpu_ids=None, gpus=None, launcher='none', local_rank=0, no_validate=False, resume_from=None, seed=None, work_dir=None)
[10/13 04:57:56] MIX INFO: Command line arguments: Namespace(config='/home/jinliang/code/mix/configs/mcan/mcan_vqa.py', eval_only=False, gpu_ids=None, gpus=None, launcher='none', local_rank=0, no_validate=False, resume_from=None, seed=None, work_dir=None)
[10/13 04:57:56] MIX INFO: Running with full config:
Config (path: /home/jinliang/code/mix/configs/mcan/mcan_vqa.py): {'model': {'type': 'MCAN', 'embedding': [{'type': 'WordEmbedding', 'vocab_file': '/home/jinliang/.cache/torch/mmf/data/datasets/textvqa/defaults/extras/vocabs/vocabulary_100k.txt', 'embedding_dim': 300}, {'type': 'TextEmbedding', 'emb_type': 'mcan', 'hidden_dim': 1024, 'embedding_dim': 300, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'num_attn_pool': 1, 'num_feat': 2}], 'encoder': {'type': 'ImageFeatureEncoder', 'encoder_type': 'default'}, 'backbone': {'type': 'TwoBranchEmbedding', 'embedding_dim': 2048, 'hidden_dim': 1024, 'cond_dim': 1024, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'cbn_num_layers': 4}, 'combine_model': {'type': 'BranchCombineLayer', 'img_dim': 1024, 'ques_dim': 1024}, 'head': {'type': 'ClassifierLayer', 'classifier_type': 'triple_linear', 'in_dim': 2048, 'out_dim': 3129}}, 'dataset_type': 'VQADATASET', 'data_root': '/home/jinliang/.cache/torch/mmf/', 'feature_path': 'data/datasets/vqa2/grid_features/features/', 'annotation_path': 'data/datasets/vqa2/grid_features/annotations/', 'vocab_path': 'data/datasets/vqa2/defaults/extras/vocabs/', 'train_datasets': ['train', 'val', 'visualgenome'], 'test_datasets': ['oneval'], 'vqa_reader_train_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val', 'visualgenome']}, 'vqa_reader_test_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler_cfg': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'train_data': {'samples_per_gpu': 2, 'workers_per_gpu': 2, 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val', 'visualgenome']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}}, 'test_data': {'samples_per_gpu': 2, 'workers_per_gpu': 2, 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}, 'eval_period': 1000}, 'evaluator_type': 'VQA', 'optimizer': {'type': 'AdamW', 'lr': 0.0001, 'weight_decay': 0, 'eps': 1e-09}, 'optimizer_config': {'grad_clip': None}, 'lr_config': {'policy': 'step', 'warmup': 'linear', 'warmup_iters': 27000, 'warmup_ratio': 0.25, 'step': [90000, 108000]}, 'max_iter': 118000, 'checkpoint_config': {'period': 100}, 'log_config': {'period': 2, 'hooks': [{'type': 'TextLoggerHook'}]}, 'dist_params': {'backend': 'nccl'}, 'log_level': 'INFO', 'work_dir': './work_dirs', 'load_from': None, 'resume_from': None, 'workflow': [('train', 1)], 'SEED': 100, 'eval_only': False, 'gpu_ids': range(0, 1), 'distributed': False}
[10/13 04:57:56] MIX INFO: Running with full config:
Config (path: /home/jinliang/code/mix/configs/mcan/mcan_vqa.py): {'model': {'type': 'MCAN', 'embedding': [{'type': 'WordEmbedding', 'vocab_file': '/home/jinliang/.cache/torch/mmf/data/datasets/textvqa/defaults/extras/vocabs/vocabulary_100k.txt', 'embedding_dim': 300}, {'type': 'TextEmbedding', 'emb_type': 'mcan', 'hidden_dim': 1024, 'embedding_dim': 300, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'num_attn_pool': 1, 'num_feat': 2}], 'encoder': {'type': 'ImageFeatureEncoder', 'encoder_type': 'default'}, 'backbone': {'type': 'TwoBranchEmbedding', 'embedding_dim': 2048, 'hidden_dim': 1024, 'cond_dim': 1024, 'num_attn': 8, 'dropout': 0.1, 'num_layers': 6, 'cbn_num_layers': 4}, 'combine_model': {'type': 'BranchCombineLayer', 'img_dim': 1024, 'ques_dim': 1024}, 'head': {'type': 'ClassifierLayer', 'classifier_type': 'triple_linear', 'in_dim': 2048, 'out_dim': 3129}}, 'dataset_type': 'VQADATASET', 'data_root': '/home/jinliang/.cache/torch/mmf/', 'feature_path': 'data/datasets/vqa2/grid_features/features/', 'annotation_path': 'data/datasets/vqa2/grid_features/annotations/', 'vocab_path': 'data/datasets/vqa2/defaults/extras/vocabs/', 'train_datasets': ['train', 'val', 'visualgenome'], 'test_datasets': ['oneval'], 'vqa_reader_train_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val', 'visualgenome']}, 'vqa_reader_test_cfg': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler_cfg': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}, 'train_data': {'samples_per_gpu': 2, 'workers_per_gpu': 2, 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['train', 'val', 'visualgenome']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}}, 'test_data': {'samples_per_gpu': 2, 'workers_per_gpu': 2, 'data': {'type': 'VQADATASET', 'vqa_reader': {'type': 'VQAReader', 'mmf_features': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/train2014', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/test2015', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/visualgenome', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/features/val2014'}, 'mmf_annotations': {'train': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_train2014.npy', 'val': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_val2014.npy', 'test': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_test2015.npy', 'visualgenome': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_visualgenome.npy', 'oneval': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/grid_features/annotations/imdb_oneval2014.npy'}, 'datasets': ['oneval']}, 'vqa_info_cpler': {'type': 'VQAInfoCpler', 'glove_weights': '/home/jinliang/.cache/torch/mmf/glove.6B.300d.txt.pt', 'tokenizer': '/home/datasets/VQA/bert/bert-base-uncased-vocab.txt', 'mmf_vocab': {'answers_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/answers_vqa.txt', 'vocabulart_100k': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_100k.txt', 'vocabulary_vqa': '/home/jinliang/.cache/torch/mmf/data/datasets/vqa2/defaults/extras/vocabs/vocabulary_vqa.txt'}}}, 'eval_period': 1000}, 'evaluator_type': 'VQA', 'optimizer': {'type': 'AdamW', 'lr': 0.0001, 'weight_decay': 0, 'eps': 1e-09}, 'optimizer_config': {'grad_clip': None}, 'lr_config': {'policy': 'step', 'warmup': 'linear', 'warmup_iters': 27000, 'warmup_ratio': 0.25, 'step': [90000, 108000]}, 'max_iter': 118000, 'checkpoint_config': {'period': 100}, 'log_config': {'period': 2, 'hooks': [{'type': 'TextLoggerHook'}]}, 'dist_params': {'backend': 'nccl'}, 'log_level': 'INFO', 'work_dir': './work_dirs', 'load_from': None, 'resume_from': None, 'workflow': [('train', 1)], 'SEED': 100, 'eval_only': False, 'gpu_ids': range(0, 1), 'distributed': False}
[10/13 04:58:11] MIX INFO: Full config saved to ./work_dirs/config.yaml
[10/13 04:58:11] MIX INFO: Full config saved to ./work_dirs/config.yaml
